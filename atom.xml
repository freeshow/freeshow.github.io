<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>FreeShow</title>
  <subtitle>在追求艺术的道路上狂奔</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://freeshow.github.io/"/>
  <updated>2017-03-28T08:52:26.644Z</updated>
  <id>https://freeshow.github.io/</id>
  
  <author>
    <name>FreeShow</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hadoop分布式集群安装</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/Hadoop分布式集群安装/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:52:26.644Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<p>转载声明：<br>本教程转载自：厦门大学数据库实验室 blog<br><a href="http://dblab.xmu.edu.cn/blog/install-hadoop/" target="_blank" rel="external">Hadoop安装教程_单机/伪分布式配置_Hadoop2.6.0/Ubuntu14.04</a><br><a href="http://dblab.xmu.edu.cn/blog/install-hadoop-cluster/" target="_blank" rel="external">Hadoop集群安装配置教程_Hadoop2.6.0_Ubuntu/CentOS</a></p>
<h1 id="一、环境搭建"><a href="#一、环境搭建" class="headerlink" title="一、环境搭建"></a>一、环境搭建</h1><h2 id="1-使用VirtualBox创建三台Ubuntu-Server-14-04-64-位-虚拟机"><a href="#1-使用VirtualBox创建三台Ubuntu-Server-14-04-64-位-虚拟机" class="headerlink" title="1.使用VirtualBox创建三台Ubuntu Server 14.04(64 位)虚拟机"></a>1.使用VirtualBox创建三台Ubuntu Server 14.04(64 位)虚拟机</h2><p>首先，使用VirtualBox安装3台Ubuntu Server，主机名分别为master,slave1,slave2，各用户名均为hadoop.<br>如图所示：</p>
<p><img src="http://i.imgur.com/T4lUiC7.png" alt=""></p>
<p><img src="http://i.imgur.com/RLAaMQc.png" alt=""></p>
<h2 id="2-配置网络"><a href="#2-配置网络" class="headerlink" title="2.配置网络"></a>2.配置网络</h2><p>使用虚拟机安装的系统，需要更改网络连接方式为桥接（Bridge）模式，才能实现多个节点互连。<br>例如在VirturalBox中的设置如下图。此外，如果节点的系统是在虚拟机中直接复制的，要确保各个节点的Mac地址不同（可以点右边的按钮随机生成MAC地址，否则IP会冲突）：</p>
<p><img src="http://i.imgur.com/9bXwfCr.png" alt=""></p>
<h2 id="3-添加主机名与IP的对应关系"><a href="#3-添加主机名与IP的对应关系" class="headerlink" title="3.添加主机名与IP的对应关系"></a>3.添加主机名与IP的对应关系</h2><h3 id="1-各节点与IP对应关系："><a href="#1-各节点与IP对应关系：" class="headerlink" title="(1)各节点与IP对应关系："></a>(1)各节点与IP对应关系：</h3><table>
<thead>
<tr>
<th style="text-align:center">用户名</th>
<th style="text-align:center">主机名</th>
<th style="text-align:center">IP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">hadoop</td>
<td style="text-align:center">master</td>
<td style="text-align:center">192.168.1.104</td>
</tr>
<tr>
<td style="text-align:center">hadoop</td>
<td style="text-align:center">slave1</td>
<td style="text-align:center">192.168.1.105</td>
</tr>
<tr>
<td style="text-align:center">hadoop</td>
<td style="text-align:center">slave2</td>
<td style="text-align:center">192.168.1.106</td>
</tr>
</tbody>
</table>
<h3 id="2-添加对应关系"><a href="#2-添加对应关系" class="headerlink" title="(2)添加对应关系"></a>(2)添加对应关系</h3><p>在 <code>/etc/hosts</code> 中将该映射关系填写上去即可，如下图所示：</p>
<blockquote>
<p>一般该文件中只有一个 127.0.0.1，其对应名为 localhost，如果有多余的应删除，特别是不能有 “127.0.0.1 master” 这样的记录</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vi /etc/hosts</div></pre></td></tr></table></figure>
<p>修改如下图：<br><img src="http://i.imgur.com/ENKuoXG.png" alt=""></p>
<blockquote>
<p>需要在所有节点上完成上述配置，<br>如上面讲的是master节点的配置，而在其他的slave节点上，也要对<code>/etc/hosts</code>（跟 master 的配置一样）文件进行修改！</p>
</blockquote>
<h3 id="3-测试各节点的连通性"><a href="#3-测试各节点的连通性" class="headerlink" title="(3)测试各节点的连通性"></a>(3)测试各节点的连通性</h3><p>配置好后需要在各个节点上执行如下命令，测试是否相互 ping 得通，如果 ping 不通，后面就无法顺利配置成功：<br>以master节点为例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ping slave1 -c 3		# 只ping 3次，否则要按 Ctrl+c 中断</div><div class="line">ping slave2 -c 3</div></pre></td></tr></table></figure></p>
<p>如下图所示：<br><img src="http://i.imgur.com/AUPaYbF.png" alt=""></p>
<h1 id="二、安装SSH、配置SSH无密码登陆"><a href="#二、安装SSH、配置SSH无密码登陆" class="headerlink" title="二、安装SSH、配置SSH无密码登陆"></a>二、安装SSH、配置SSH无密码登陆</h1><p><strong>这个操作是要让 master 节点可以无密码 SSH 登陆到各个 slave 节点上。</strong></p>
<h2 id="1-安装SSH"><a href="#1-安装SSH" class="headerlink" title="1. 安装SSH"></a>1. 安装SSH</h2><p>集群、单节点模式都需要用到 SSH 登陆（类似于远程登陆，你可以登录某台 Linux 主机，并且在上面运行命令）。<br>因此，需要安装 SSH client 和 SSH server：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install openssh-server openssh-client</div></pre></td></tr></table></figure>
<blockquote>
<p>安装完成后，就可以在Windows下使用SSH工具登录，上面三台虚拟机了。</p>
</blockquote>
<h2 id="2-master免密码登录本机"><a href="#2-master免密码登录本机" class="headerlink" title="2. master免密码登录本机"></a>2. master免密码登录本机</h2><p>安装完成后，可以使用如下命令登陆本机:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh localhost</div></pre></td></tr></table></figure></p>
<p>此时会有如下提示(SSH首次登陆提示)，输入 yes 。然后按提示输入密码 hadoop，这样就登陆到本机了。如下图所示：</p>
<p><img src="http://i.imgur.com/hLkCf8M.png" alt=""></p>
<blockquote>
<p>此时，在~/下，如果没有<code>.ssh</code>文件夹，则会自动创建<code>~/.ssh</code>文件夹。</p>
</blockquote>
<p>但这样登陆是需要每次输入密码的，我们需要配置成SSH无密码登陆比较方便。</p>
<p>首先退出刚才的 ssh，就回到了我们原先的终端窗口，然后利用 ssh-keygen 生成密钥，并将密钥加入到授权中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">exit                           # 退出刚才的 ssh localhost</div><div class="line">cd ~/.ssh/                     # 若没有该目录，请先执行一次ssh localhost</div><div class="line">ssh-keygen -t rsa              # 会有提示，都按回车就可以</div><div class="line">cat ./id_rsa.pub &gt;&gt; ./authorized_keys  # 加入授权</div></pre></td></tr></table></figure>
<p>此时再用 ssh localhost 命令，无需输入密码就可以直接登陆了.</p>
<blockquote>
<p>只在master节点上配置ssh免密码登录本机即可，其它slave节点不需要配置。</p>
</blockquote>
<h2 id="3-master免密码登录slaves"><a href="#3-master免密码登录slaves" class="headerlink" title="3. master免密码登录slaves"></a>3. master免密码登录slaves</h2><p>在 master 节点将上公匙传输到 slave1 节点：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scp ~/.ssh/id_rsa.pub hadoop@slave1:~</div></pre></td></tr></table></figure></p>
<blockquote>
<p>scp 是 secure copy 的简写，用于在 Linux 下进行远程拷贝文件，类似于 cp 命令，不过 cp 只能在本机中拷贝。<br>执行 scp 时会要求输入 slave1 上 hadoop 用户的密码(hadoop)，输入完成后会提示传输完毕</p>
</blockquote>
<p>接着在 slave1 节点上，将 ssh 公匙加入授权：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir ~/.ssh       # 如果不存在该文件夹需先创建，若已存在则忽略</div><div class="line">cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</div><div class="line">rm ~/id_rsa.pub    # 用完就可以删掉了</div></pre></td></tr></table></figure></p>
<p>如果有其他 slave 节点，也要执行将 master 公匙传输到 slave 节点、在 slave 节点上加入授权这两步。</p>
<p>这样，在 master 节点上就可以无密码 SSH 到各个 slave 节点了，可在 master 节点上执行如下命令进行检验，如下图所示：</p>
<p><img src="http://i.imgur.com/no5qaV8.png" alt=""></p>
<h1 id="三、安装Java环境"><a href="#三、安装Java环境" class="headerlink" title="三、安装Java环境"></a>三、安装Java环境</h1><p>查看我的博客：Ubuntu14.04安装JDK与配置环境变量</p>
<p>在各节点上都需要安装java环境。</p>
<h1 id="四、安装hadoop集群"><a href="#四、安装hadoop集群" class="headerlink" title="四、安装hadoop集群"></a>四、安装hadoop集群</h1><p>在master节点上：</p>
<h2 id="1-下载hadoop压缩包"><a href="#1-下载hadoop压缩包" class="headerlink" title="1.下载hadoop压缩包"></a>1.下载hadoop压缩包</h2><p>首先，去apache hadoop官网下载，hadoop压缩包，我下载的为：<code>hadoop-2.6.4.tar.gz</code></p>
<h2 id="2-解压"><a href="#2-解压" class="headerlink" title="2.解压"></a>2.解压</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxvf hadoop-2.6.4.tar.gz -C /opt	#解压到/opt下</div><div class="line">sudo mv hadoop-2.6.4 hadoop		#重命名为hadoop</div></pre></td></tr></table></figure>
<p>此时，压缩包被解压到/opt/hadoop下</p>
<h2 id="3-修改配置文件"><a href="#3-修改配置文件" class="headerlink" title="3.修改配置文件"></a>3.修改配置文件</h2><p>集群/分布式模式需要修改 /opt/hadoop/etc/hadoop 中的6个配置文件，更多设置项可点击查看官方说明，这里仅设置了正常启动所必须的设置项： hadoop-env.sh、slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml 。</p>
<p>(1)hadoop-env.sh</p>
<p>修改JAVA_HOME,改为绝对路径，hadoop有时不能读取<code>$JAVA_HOME</code>的值.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># The java implementation to use.</div><div class="line">export JAVA_HOME=/opt/java</div></pre></td></tr></table></figure></p>
<p>(2)slaves<br>文件 slaves，将作为 DataNode 的主机名写入该文件，每行一个，默认为 localhost，所以在伪分布式配置时，节点即作为 NameNode 也作为 DataNode。分布式配置可以保留 localhost，也可以删掉，让 Master 节点仅作为 NameNode 使用。</p>
<p>本教程让 master 节点仅作为 NameNode 使用，因此将文件中原来的 localhost 删除，添加两行内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">slave1</div><div class="line">slave2</div></pre></td></tr></table></figure></p>
<p>(3)core-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">                &lt;value&gt;hdfs://master:9000&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">                &lt;value&gt;file:/opt/hadoop/tmp&lt;/value&gt;</div><div class="line">                &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>(4)hdfs-site.xml</p>
<p>文件 hdfs-site.xml，dfs.replication 一般设为 3，但我们有两个 slave 节点，所以 dfs.replication 的值还是设为 2：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">                &lt;value&gt;Master:50090&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">                &lt;value&gt;2&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">                &lt;value&gt;file:/opt/hadoop/tmp/dfs/name&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">                &lt;value&gt;file:/opt/hadoop/tmp/dfs/data&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>(5)mapred-site.xml</p>
<p>文件 mapred-site.xml （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">                &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">                &lt;value&gt;Master:10020&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">                &lt;value&gt;Master:19888&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>(6)yarn-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</div><div class="line">                &lt;value&gt;Master&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">        &lt;property&gt;</div><div class="line">                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h2 id="4-配置好后，将master上的-opt-Hadoop文件夹复制到各个节点上。"><a href="#4-配置好后，将master上的-opt-Hadoop文件夹复制到各个节点上。" class="headerlink" title="4.配置好后，将master上的/opt/Hadoop文件夹复制到各个节点上。"></a>4.配置好后，将master上的<code>/opt/Hadoop</code>文件夹复制到各个节点上。</h2><p>在master节点上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tar -zcf ~/hadoop.master.tar.gz /opt/hadoop   # 先压缩再复制</div><div class="line">cd ~</div><div class="line">scp ./hadoop.master.tar.gz slave1:/home/hadoop	#复制到slave1上</div><div class="line">scp ./hadoop.master.tar.gz slave2:/home/hadoop	#复制到slave2上</div></pre></td></tr></table></figure>
<p>在slave1节点上执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxf ~/hadoop.master.tar.gz -C /opt</div><div class="line">sudo chown -R hadoop:hadoop /opt/hadoop</div></pre></td></tr></table></figure></p>
<p>在slave2节点上执行的与在slave1节点上执行的相同。</p>
<p>注意：</p>
<blockquote>
<p>需要保证/opt/hadoop权限属于hadoop:hadoop,如果不是执行：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo chown -R hadoop:hadoop /opt/hadoop</div></pre></td></tr></table></figure>
<p>如下图所示：</p>
<p><img src="http://i.imgur.com/i2txxn9.png" alt=""></p>
<h2 id="五、运行hadoop集群"><a href="#五、运行hadoop集群" class="headerlink" title="五、运行hadoop集群"></a>五、运行hadoop集群</h2><h3 id="1-配置hadoop环境变量"><a href="#1-配置hadoop环境变量" class="headerlink" title="1.配置hadoop环境变量"></a>1.配置hadoop环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vi /etc/profile</div></pre></td></tr></table></figure>
<p>在最后添加如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#set hadoop env</div><div class="line">export HADOOP_HOME=/opt/hadoop</div><div class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</div></pre></td></tr></table></figure></p>
<h3 id="2-启动hadoop集群"><a href="#2-启动hadoop集群" class="headerlink" title="2.启动hadoop集群"></a>2.启动hadoop集群</h3><p>首次启动需要先在 master 节点执行 NameNode 的格式化：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs namenode -format       # 首次运行需要执行初始化，之后不需要。</div></pre></td></tr></table></figure></p>
<p>接着，可以启动 hadoop 了，启动需要在 master 节点上进行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">start-dfs.sh</div><div class="line">start-yarn.sh</div><div class="line">mr-jobhistory-daemon.sh start historyserver</div></pre></td></tr></table></figure></p>
<p>通过命令 <code>jps</code> 可以查看各个节点所启动的进程。正确的话，在 master 节点上可以看到 NameNode、ResourceManager、SecondrryNameNode、JobHistoryServer 进程，如下图所示：</p>
<p><img src="http://i.imgur.com/VBZrruo.png" alt="通过jps查看master的Hadoop进程"></p>
<p>在 slave 节点可以看到 DataNode 和 NodeManager 进程，如下图所示：</p>
<p><img src="http://i.imgur.com/mZCwp1f.png" alt="通过jps查看slave的Hadoop进程"></p>
<p>缺少任一进程都表示出错。另外还需要在 master 节点上通过命令 hdfs dfsadmin -report 查看 DataNode 是否正常启动，如果 Live datanodes 不为 0 ，则说明集群启动成功。例如我这边一共有 2 个 Datanodes：</p>
<p><img src="http://i.imgur.com/K25fzmw.png" alt=""></p>
<p>也可以通过 Web 页面看到查看 DataNode 和 NameNode 的状态：<a href="http://master:50070/" target="_blank" rel="external">http://master:50070/</a>。如果不成功，可以通过启动日志排查原因。</p>
<p>由于本教程是在Windows上使用VirtualBox开启了master、slave1、slave2,3个虚拟机，如果要访问<a href="http://master:50070" target="_blank" rel="external">http://master:50070</a>,需要将Windows中的hosts文件中添加一行映射地址：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">192.168.1.104	master</div></pre></td></tr></table></figure></p>
<p>笔者用的是Win10 64位系统，hosts文件在<code>C:\Windows\System32\drivers\etc</code>下，用notepad++打开，添加上面一行即可。</p>
<p>配置完hosts文件后，打开浏览器，输入网址：<a href="http://master:50070" title="http://master:50070" target="_blank" rel="external">http://master:50070</a>，可以看到如下图效果：</p>
<p><img src="http://i.imgur.com/E7vpxN6.png" alt=""></p>
<h2 id="六、在hadoop集群上，执行分布式实例"><a href="#六、在hadoop集群上，执行分布式实例" class="headerlink" title="六、在hadoop集群上，执行分布式实例"></a>六、在hadoop集群上，执行分布式实例</h2><p>首先，在 HDFS 上创建用户目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -mkdir -p /user/hadoop</div></pre></td></tr></table></figure>
<p>将 /etc/hadoop/etc/hadoop 中的配置文件作为输入文件复制到分布式文件系统中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -mkdir input</div><div class="line">hdfs dfs -put /opt/hadoop/etc/hadoop/*.xml input</div></pre></td></tr></table></figure>
<p>通过查看 DataNode 的状态（占用大小有改变），输入文件确实复制到了 DataNode 中，如下图所示:</p>
<p><img src="http://i.imgur.com/ISH8yzd.png" alt="通过Web页面查看DataNode的状态"></p>
<p>接着就可以运行 MapReduce 作业了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar grep input output &apos;dfs[a-z.]+&apos;</div></pre></td></tr></table></figure>
<p>运行时的输出信息，会显示 Job 的进度,如下图所示：</p>
<p><img src="http://i.imgur.com/Rdi4gJN.png" alt=""></p>
<p>同样可以通过 Web 界面查看任务进度 <a href="http://master:8088/cluster" target="_blank" rel="external">http://master:8088/cluster</a>，在 Web 界面点击 “Tracking UI” 这一列的 History 连接，可以看到任务的运行信息，如下图所示：</p>
<p><img src="http://i.imgur.com/F2MIQSP.png" alt=""></p>
<p>执行完毕后的输出结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -cat output/*</div></pre></td></tr></table></figure></p>
<p>结果，如下图所示：</p>
<p><img src="http://i.imgur.com/2O4Gudh.png" alt=""></p>
<p>##最后，注意：</p>
<p>如果，上面配置教程中用到的安装包或文件，是从Windows上传到虚拟机的，需要更改上传文件的权限：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo chown -R hadoop:hadoop 上传文件</div></pre></td></tr></table></figure>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hive应用实例：WordCount</title>
    <link href="https://freeshow.github.io/BigData/Hive/Hive%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B%EF%BC%9AWordCount/"/>
    <id>https://freeshow.github.io/BigData/Hive/Hive应用实例：WordCount/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:55:18.924Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<p>出自《大数据原理与应用》一书。</p>
<h1 id="词频统计任务要求："><a href="#词频统计任务要求：" class="headerlink" title="词频统计任务要求："></a>词频统计任务要求：</h1><p>首先，需要创建一个需要分析的输入数据文件<br>然后，编写HiveQL语句实现WordCount算法</p>
<p>#具体步骤如下：</p>
<h2 id="（1）创建input目录，其中input为输入目录。命令如下："><a href="#（1）创建input目录，其中input为输入目录。命令如下：" class="headerlink" title="（1）创建input目录，其中input为输入目录。命令如下："></a>（1）创建input目录，其中input为输入目录。命令如下：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ cd /home/hadoop</div><div class="line">$ mkdir input</div></pre></td></tr></table></figure>
<p>##（2）在input文件夹中创建两个测试文件file1.txt和file2.txt，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ cd  /home/hadoop/input</div><div class="line">$ echo &quot;hello world&quot; &gt; file1.txt</div><div class="line">$ echo &quot;hello hadoop&quot; &gt; file2.txt</div></pre></td></tr></table></figure></p>
<p>##（3）进入hive命令行界面，编写HiveQL语句实现WordCount算法，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ hive</div><div class="line">hive&gt; create table docs(line string);</div><div class="line">hive&gt; load data inpath &apos;input&apos; overwrite into table docs;</div><div class="line">hive&gt;create table word_count as </div><div class="line">     select word, count(1) as count from</div><div class="line">     (select explode(split(line,&apos; &apos;))as word from docs) w</div><div class="line">     group by word</div><div class="line">     order by word;</div></pre></td></tr></table></figure></p>
<center><img src="http://i.imgur.com/nwNRG38.png" alt=""></center><br><center><img src="http://i.imgur.com/gup2ShW.png" alt=""></center>

<p><strong>执行完成后，用select语句查看运行结果如下：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hive&gt; select * from word_count;</div><div class="line">OK</div><div class="line">hadoop  1</div><div class="line">hello   2</div><div class="line">world   1</div><div class="line">Time taken: 0.111 seconds, Fetched: 3 row(s)</div><div class="line">hive&gt;</div></pre></td></tr></table></figure></p>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hive安装</title>
    <link href="https://freeshow.github.io/BigData/Hive/Hive%E5%AE%89%E8%A3%85/"/>
    <id>https://freeshow.github.io/BigData/Hive/Hive安装/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T11:30:15.546Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<p>因为Hive是构建在Hadoop之上的，所以在安装Hive前，我们需要安装Hadoop环境。<br>Hadoop的安装可以参考<a href="https://freeshow.github.io/BigData/Hadoop/Hadoop分布式集群安装/">Hadoop分布式集群安装</a></p>
<p>本教程使用Hive的本地模式进行安装，本地模式下Hive使用MySQL作为作为元数据库。</p>
<h1 id="一、安装MySQL"><a href="#一、安装MySQL" class="headerlink" title="一、安装MySQL"></a>一、安装MySQL</h1><h2 id="1-安装MySQL"><a href="#1-安装MySQL" class="headerlink" title="1.安装MySQL"></a>1.安装MySQL</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install mysql-server mysql-client</div></pre></td></tr></table></figure>
<h2 id="2-允许MySQL远程连接"><a href="#2-允许MySQL远程连接" class="headerlink" title="2.允许MySQL远程连接"></a>2.允许MySQL远程连接</h2><p>默认情况下，MySQL只允许本地登录，所以需要修改 my.cnf 配置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo vi /etc/mysql/my.cnf</div><div class="line">#bind-address=127.0.0.1</div></pre></td></tr></table></figure>
<p>注释掉上一句即可在任意位置登录MySQL，然后重启MySQL：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo service mysql restart</div></pre></td></tr></table></figure>
<h2 id="3-创建MySQL用户和数据库"><a href="#3-创建MySQL用户和数据库" class="headerlink" title="3.创建MySQL用户和数据库"></a>3.创建MySQL用户和数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">#登录MySQL</div><div class="line">mysql -u root -p</div><div class="line"></div><div class="line">#创建hive数据库</div><div class="line">create database hive;</div><div class="line"></div><div class="line">#创建MySQL用户hive</div><div class="line">grant all on hive.* to hive@&apos;%&apos; identified by &apos;hive&apos;;</div><div class="line">grant all on hive.* to hive@&apos;localhost&apos; identified by &apos;hive&apos;; </div><div class="line">flush privileges;</div><div class="line">exit                   #退出mysql</div><div class="line"></div><div class="line">#验证hive用户</div><div class="line">mysql -u hive -p hive        </div><div class="line">show databases;</div></pre></td></tr></table></figure>
<h1 id="二、安装Hive"><a href="#二、安装Hive" class="headerlink" title="二、安装Hive"></a>二、安装Hive</h1><h2 id="1-解压软件包"><a href="#1-解压软件包" class="headerlink" title="1.解压软件包"></a>1.解压软件包</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxvf apache-hive-2.1.0-bin.tar.gz -C /opt/ #解压到/opt目录下</div><div class="line">cd /opt</div><div class="line">sudo mv apache-hive-2.1.0 hive	#重名名为hive</div><div class="line">sudo chown -R hadoop:hadoop hive #修改hive目录拥有者</div></pre></td></tr></table></figure>
<h2 id="2-配置Hive的环境变量"><a href="#2-配置Hive的环境变量" class="headerlink" title="2.配置Hive的环境变量"></a>2.配置Hive的环境变量</h2><p>在 <code>/etc/profile</code>文件名末尾添加如下内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># set hive</div><div class="line">export HIVE_HOME=/opt/hive</div><div class="line">export PATH=$PATH:$HIVE_HOME/bin</div></pre></td></tr></table></figure>
<p>使profile发挥作用：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">source /etc/profile</div></pre></td></tr></table></figure></p>
<h2 id="3-修改Hive配置文件"><a href="#3-修改Hive配置文件" class="headerlink" title="3.修改Hive配置文件"></a>3.修改Hive配置文件</h2><p>（1）修改hive-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd /opt/hive/config</div><div class="line">cp hive-env.sh.template hive-env.sh</div><div class="line">sudo vi hive-env.sh</div></pre></td></tr></table></figure>
<p>在<code>hive-env.sh</code>文件末尾添加变量指向Hadoop的安装路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">HADOOP_HOME=/opt/hadoop</div></pre></td></tr></table></figure></p>
<p>（2）修改hive-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cp hive-default.xml.template hive-site.xml</div><div class="line">sudo vi hive-site.xml</div></pre></td></tr></table></figure></p>
<p>修改<code>hive-site.xml</code>的主要内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</div><div class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://127.0.0.1:3306/hive?createDatebaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword <span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.Multithreaded<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>上面配置的说明：</p>
<ul>
<li>hive.exec.scratchdir: 执行Hive操作访问HDFS时用于存储临时数据的目录，默认为/tmp/目录，通常设置为/tmp/hive/,目录权限设置为733.</li>
<li>hive.metastore.warehouse.dir: 执行Hive数据仓库操作的数据存储目录，设置为HDFS存储路径<code>hdfs://master_hostname:port/hive/warehouse</code>。</li>
<li>javax.jdo.option.ConnectionURL: 设置Hive通过JDBC模式连接MySQL数据库存储metastore内容。</li>
</ul>
<p>创建上述配置中的目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -mkdir /tmp/hive</div><div class="line">hdfs dfs -mkdir /hive/warehouse</div><div class="line"></div><div class="line">#分别对刚创建的目录添加组可写权限，允许同组用户进行数据分析操作</div><div class="line">hdfs dfs -chmod g+w /tmp</div><div class="line">hdfs dfs -chmod g+w /hive/warehouse</div></pre></td></tr></table></figure></p>
<h2 id="4-添加MySQL-JDBC驱动"><a href="#4-添加MySQL-JDBC驱动" class="headerlink" title="4.添加MySQL JDBC驱动"></a>4.添加MySQL JDBC驱动</h2><p>下载MySQL JDBC驱动，并放在 <code>$HIVE_HOME/lib</code>目录下</p>
<hr>
<p>经过上述Hive的基本安装和配置步骤后，在Linux命令提示符下输入hive命令即可进入Hive Shell交互模式环境中进行Hive相关的操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hive</div><div class="line">hive&gt;</div></pre></td></tr></table></figure>
<p>如果执行hive命令出现如下错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Exception in thread &quot;main&quot; java.lang.RuntimeException: </div><div class="line">Hive metastore database is not initialized. </div><div class="line">Please use schematool (e.g. ./schematool -initSchema -dbType ...) to create the schema. </div><div class="line">If needed, don&apos;t forget to include the option to auto-create the underlying database in your JDBC connection string (e.g. ?createDatabaseIfNotExist=true for mysql)</div></pre></td></tr></table></figure></p>
<p>可执行如下命令解决：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">schematool -dbType mysql -initSchema</div></pre></td></tr></table></figure></p>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Windows下使用Eclipse插件运行自己的MapReduce程序</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/Windows%E4%B8%8B%E4%BD%BF%E7%94%A8eclipse%E6%8F%92%E4%BB%B6%E8%BF%90%E8%A1%8C%E8%87%AA%E5%B7%B1%E7%9A%84MapReduce%E7%A8%8B%E5%BA%8F/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/Windows下使用eclipse插件运行自己的MapReduce程序/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T11:27:52.532Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<p>在上一篇博客中：<a href="https://freeshow.github.io/BigData/Hadoop/Windows%E4%B8%8B%E4%BD%BF%E7%94%A8eclipse%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E8%BF%90%E8%A1%8C%E8%87%AA%E5%B7%B1%E7%9A%84MapReduce%E7%A8%8B%E5%BA%8F%20Hadoop2.6.0/">Windows下使用eclipse编译打包运行自己的MapReduce程序</a> 中，开发完成的jar包需要上传到集群并使用相应的命令才能执行，这对不熟悉Linux的用户仍具有一定困难，而使用Hadoop Eclipse插件能很好的解决这一问题。</p>
<p>Hadoop Eclipse插件不仅能让用户直接在本地(Windows下)提交任务到Hadoop集群上，还能调试代码、查看出错信息和结果、使用图形化的方式管理HDFS文件。</p>
<p>Hadoop Eclipse插件需要单独从网上获取，获取后，可以自己重编译，也可直接使用编译好的release版本，经过测试，笔者发现从网上获取的插件可以直接使用，下面介绍如何获取和简单使用Eclipse插件。</p>
<h1 id="一、获取Hadoop-Eclipse插件"><a href="#一、获取Hadoop-Eclipse插件" class="headerlink" title="一、获取Hadoop Eclipse插件"></a>一、获取Hadoop Eclipse插件</h1><p>获取Hadoop Eclipse插件的地址是：<a href="https://github.com/winghc/hadoop2x-eclipse-plugin" target="_blank" rel="external">https://github.com/winghc/hadoop2x-eclipse-plugin</a></p>
<p>本文使用的是hadoop-2.6.4，所以使用的插件版本是<code>hadoop-eclipse-plugin-2.6.0.jar</code>。</p>
<h1 id="二、使用Hadoop-Eclipse插件"><a href="#二、使用Hadoop-Eclipse插件" class="headerlink" title="二、使用Hadoop Eclipse插件"></a>二、使用Hadoop Eclipse插件</h1><p>在Eclipse中使用插件非常简单，对于本文所使用的Eclipse Jee版本，只需要关闭Eclipse，把上述插件复制到 <code>Eclipse\dropins</code>目录下，在重新打开Eclipse即可。对于其他的Eclipse版本，可能需要复制到 <code>Eclipse\plugins</code> 目录下。</p>
<h2 id="1-查找Eclipse插件"><a href="#1-查找Eclipse插件" class="headerlink" title="1.查找Eclipse插件"></a>1.查找Eclipse插件</h2><p>启动Eclipse后，依次点击 Windows -&gt; Show View -&gt; Other。在新弹出的选项框中找到 <code>Map/Reduce Locations</code>， 选中后单击 OK 按钮。如下图所示：</p>
<center><img src="http://i.imgur.com/cIfR0k2.png" alt=""></center>

<p>单击 OK 后，在Eclipse下面的视图中会多出一栏 Map/Reduce Locations,如下图所示：</p>
<center><img src="http://i.imgur.com/Fue1psJ.png" alt=""></center>

<p>然后单击 Windows -&gt; Show View -&gt; Project Expore,在Eclipse左侧视图中会显示项目浏览器，项目浏览器中最上面会出现 DFS Locations,如下图所示：</p>
<center><img src="http://i.imgur.com/rSfDgLQ.png" alt=""></center>

<p>Map/Reduce Locations 用于建立连接到Hadoop 集群，当连接到Hadoop集群后，DFS Locations 则会显示相应集群 HDFS 中的文件。 Map/Reduce Locations 可以一次连接到多个Hadoop集群。</p>
<p>在 Map/Reduce Locations 下侧的空白处右击，在弹出的选项中选择 New Hadoop location,新建一个Hadoop连接，之后会弹出 Hadoop location 的详细设置窗口，如下图所示，各项解释如下。</p>
<ul>
<li>Location name: 当前建立的Hadoop location命名。</li>
<li>Map/Reduce Host: 为集群nomenode的IP地址。</li>
<li>Map/Reduce Port: MapReduce任务运行的通信端口号，客户端通过该地址向RM提交应用程序，杀死应用程序等。在yarn-site.xml中，默认值：${yarn.resourcemanager.hostname}:8032 </li>
<li>DFS Master Use M/R Master host: 选中表示采用和 Map/Reduce Host一样的主机。</li>
<li>DFS Naster Host： 为集群namenode的IP地址。</li>
<li>DFS Master Port: HDFS端口号，对应core-site.xml中定义的fs.defaultFS参数中的端口号，一般为9000;</li>
<li>User Name:设置访问集群的用户名，默认为本机的用户名。</li>
</ul>
<center><img src="http://i.imgur.com/okOUyOd.png" alt=""></center>

<p>配置完成后，单击Finish即可完成 Hadoop location的配置。在 Advanced parameters选项卡中还可以配置更多细节，但在实际使用中非常繁琐，<font color="red">相应的设置在代码中也可以进行，或者将Hadoop集群的配置文件放到Eclipse目录下，自动完整配置。</font> 这里只需要配置General选项卡的内容即可。这是，右侧Project Expore中的DFS locations中会多出一个子栏，名字为上面设置的Hadoop location名称。</p>
<h2 id="2-使用Eclipse插件管理HDFS"><a href="#2-使用Eclipse插件管理HDFS" class="headerlink" title="2.使用Eclipse插件管理HDFS"></a>2.使用Eclipse插件管理HDFS</h2><p>如果前面的配置参数没有问题，Hadoop集群也已经启动，那么Eclipse插件会自动连接Hadoop集群的HDFS，并获取HDFS的文件信息。变可以在上面操作HDFS。</p>
<p>需要注意的是，<code>Refresh</code>只对选中的项目有效，如果是文件，那么只刷新该文件的相关信息；如果是文件夹，则只刷新该文件夹下的内容。</p>
<p>还需要值的一提的是，为了安全，HDFS的权限检测机制默认是打开的，关闭之后，才能使用Eclipse插件上传文件到HDFS或者从HDFS中删除文件。</p>
<p>为了能在Windows上直接操作Hadoop集群中的HDFS:</p>
<p>第一步：<br>如果只在测试环境下，直接把Hadoop集群中的HDFS的权限检测关闭，可在hdfs-site.xml中添加如下变量，重启Hadoop集群即可。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
<p>第二步：<br>修改Windows本地主机名</p>
<p>首先，“右击”桌面上图标“我的电脑”，选择“管理”，接着选择“本地用户和组”，展开“用户”，找到当前系统用户，修改其为“hadoop”。</p>
<p>最后，把电脑进行“注销”或者“重启电脑”，这样修改的用户名才有效。</p>
<p>选用上述任意一种方法以后（如果只是学习用，推荐第一种方法），就可以用Hadoop Eclipse插件提供的图像化界面操作Hadoop集群中的HDFS了。</p>
<center><img src="http://i.imgur.com/OhPtnF6.png" alt=""></center>



<h1 id="三、在Eclipse中提交任务到Hadoop"><a href="#三、在Eclipse中提交任务到Hadoop" class="headerlink" title="三、在Eclipse中提交任务到Hadoop"></a>三、在Eclipse中提交任务到Hadoop</h1><p>使用Eclipse插件可以直接在Eclipse环境下采用图形操作的方式提交任务，可以极大的简化了开发人员提交任务的步骤。</p>
<h2 id="1-配置本地Hadoop目录和输入输出目录"><a href="#1-配置本地Hadoop目录和输入输出目录" class="headerlink" title="1.配置本地Hadoop目录和输入输出目录"></a>1.配置本地Hadoop目录和输入输出目录</h2><p>首先，需要在Eclipse中设置本地Hadoop目录，假设安装hadoop的压缩包解压到本地 <code>F:\hadoop-2.6.4</code>下，在Eclipse界面单击 Windows -&gt; Preference 弹出设置界面，在设置界面找到 Hadoop Map/Reduce,在 Hadoop installation dierctory后面填上 <code>F:\hadoop-2.6.4</code></p>
<p>此处，需要注意，解压的 <code>F:\hadoop-2.6.4</code>源码包是在Linux环境下的源码包，与Windows不兼容。<br>在Windows下提交任务是会出现<code>Failed to lacation the winutils binary in hadoop binary path</code>,需要使用如下操作进行修复：<br>（1） 下载Window下的运行包<br> 将 <code>https://github.com/steveloughran/winutils/</code>项目下的 <code>hadoop-2.6.4/bin</code>目录下的所有文件覆盖掉<code>F:\hadoop-2.6.4\bin</code>下的所有文件。<br>（2） 复制<code>F:\hadoop-2.6.4\bin\hadoop.dll</code>文件到<code>C:\Windows\System32</code>中。<br>（3）配置环境变量 HADOOP_HOME为F:\hadoop-2.6.4,并将<code>$HADOOP_HOME\bin</code>添加到PATH环境变量中去。<br>（4）重启电脑。</p>
<p>在向Hadoop集群提交任务时，还需要指定输入/输出目录，在Eclipse中，可按如下操作进行设置：双击打开工程的某代码文件，在代码编辑区 右键 -&gt; Run As -&gt; Run Configurations. 在弹出的窗口中找到 Java Application -&gt; WordMain, 单击 WordMain 进入设置界面，单击 Arguments 切换选项卡，在 Program arguments 下的文本框中指定输入/输出目录。</p>
<p>第一行目录为输入目录，第二行目录为输出目录，格式为 <code>hdfs://[namenode_ip]:[端口号][路径]</code>。<br>注意，输出目录在HDFS中不能存在。如下图所示：</p>
<center><img src="http://i.imgur.com/4GjcRmn.png" alt=""></center>

<p>注意：上图中的master我已经在本地主机的hosts文件中映射为namenode的IP地址了。</p>
<h2 id="为WordCount添加配置信息。"><a href="#为WordCount添加配置信息。" class="headerlink" title="为WordCount添加配置信息。"></a>为WordCount添加配置信息。</h2><p>本次演示，使用 <a href="http://freeshow.github.io/2016/07/24/Windows下使用eclipse编译打包运行自己的MapReduce程序 Hadoop2.6.0/">Windows下使用eclipse编译打包运行自己的MapReduce程序 Hadoop2.6.0</a>中的例子。</p>
<p>添加配置信息有两种方法：<br>（1） 使用con.set()方法，设置配置信息。<br>（2） 将Hadoop集群中的修改过的配置文件，如<code>hdfs-site.xml</code>,<code>core-site.xml</code>,<code>mapred-site.xml</code>,<code>yarn-site.xml</code>,<code>log4j.properties</code>,复制到 WordCount 项目下的 src 文件夹下。</p>
<p>我比较喜欢用第二种方法。</p>
<font color="red"><strong>注意：</strong></font><br>配置信息完成后，在建立Job类对象后面也新增一行代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">job.setJar(<span class="string">"wordcount.jar"</span>);</div></pre></td></tr></table></figure><br><br>用户告诉hadoop集群所要运行的Jar文件，所以需要先导出WordCount项目为jar文件，位置位于项目根目录下，因为上面代码<code>job.setJar(&quot;wordcount.jar&quot;);</code>查找目标的相对路径为WordCount项目根目录。<br><br><font color="red"><strong>运行时出现的一个问题:</strong></font>

<p>在通过Windows客户端向Linux服务器提交Hadoop应用时，会提示如下错误：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">org.apache.hadoop.util.Shell$ExitCodeException: /bin/bash: line <span class="number">0</span>: fg: no job control</div><div class="line"></div><div class="line">        at org.apache.hadoop.util.Shell.runCommand(Shell.java:<span class="number">505</span>)</div><div class="line">        at org.apache.hadoop.util.Shell.run(Shell.java:<span class="number">418</span>)</div><div class="line">        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:<span class="number">650</span>)</div><div class="line">        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:<span class="number">195</span>)</div><div class="line">        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:<span class="number">300</span>)</div><div class="line">        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:<span class="number">81</span>)</div><div class="line">        at java.util.concurrent.FutureTask.run(FutureTask.java:<span class="number">262</span>)</div><div class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</div><div class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</div><div class="line">        at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</div></pre></td></tr></table></figure></p>
<p>解决方法是：<br>在向项目文件夹下的src目录下添加的配置文件<code>mapred-site.xml</code>中添加如下信息：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.app-submission.cross-platform<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>不需要向hadoop集群的<code>mapred-site.xml</code>配置文件中添加。</p>
<h2 id="3-提交任务"><a href="#3-提交任务" class="headerlink" title="3.提交任务"></a>3.提交任务</h2><p>提交任务非常简单，直接在代码编辑区 右键 -&gt; Run As -&gt; Run on Hadoop 即可。</p>
<h1 id="四、建立Map-Reduce项目"><a href="#四、建立Map-Reduce项目" class="headerlink" title="四、建立Map/Reduce项目"></a>四、建立Map/Reduce项目</h1><p>在应用Hadoop Eclipse插件后，可以直接在Eclipse中建立Map/Reduce项目，该项目会自动引用相应的jar包，路径为设置的本地<code>F:\hadoop-2.6.4</code>目录，所以在项目中不用再进行建立lib文件夹，复制jar包等操作。</p>
<p>在Eclipse中一次单击 File -&gt; New -&gt; Project,弹出项目类型选择对话框，选择 Map/Reduce Project,单击 Next ,在新弹出的对话框中填上项目名称：wordcount2 ，单击 Finish 即可。</p>
<p>之后再项目中建立一个<code>WordCount2</code>类，插入如下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> wordcount2;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.StringTokenizer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount2</span> </span>&#123;</div><div class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">		<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</div><div class="line">		<span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</div><div class="line">		</div><div class="line">		<span class="meta">@Override</span></div><div class="line">		<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span></span></div><div class="line">				<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">			StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</div><div class="line">			<span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</div><div class="line">				word.set(itr.nextToken());</div><div class="line">				context.write(word, one);</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">		<span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</div><div class="line">		</div><div class="line">		<span class="meta">@Override</span></div><div class="line">		<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,Context context)</span></span></div><div class="line">				<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">			<span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">			<span class="keyword">for</span>(IntWritable val : values)&#123;</div><div class="line">				sum += val.get();</div><div class="line">			&#125;</div><div class="line">			result.set(sum);</div><div class="line">			context.write(key, result);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		<span class="comment">// Configuration 类: 读取hadoop的配置文件，如 site-core.xml...;</span></div><div class="line">				<span class="comment">//也可以用set方法重新设置(会覆盖): conf.set("fs.defaultFS","hdfs://master:9000")</span></div><div class="line">				Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">				</div><div class="line">				<span class="comment">//将命令行中的参数自动设置到变量conf中</span></div><div class="line">				String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf,args).getRemainingArgs();</div><div class="line">				</div><div class="line">				<span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</div><div class="line">					System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; &lt;out&gt;"</span>);</div><div class="line">					System.exit(<span class="number">2</span>);</div><div class="line">				&#125;</div><div class="line">				</div><div class="line">			    Job job = <span class="keyword">new</span> Job(conf,<span class="string">"word count2"</span>);	<span class="comment">//新建一个job,传入配置信息</span></div><div class="line">				job.setJar(<span class="string">"wordcount2.jar"</span>);</div><div class="line">				job.setJarByClass(WordCount2.class);	<span class="comment">//设置主类</span></div><div class="line">				job.setMapperClass(TokenizerMapper.class);	<span class="comment">//设置Mapper类</span></div><div class="line">				job.setReducerClass(IntSumReducer.class);	<span class="comment">//设置Reducer类</span></div><div class="line">				job.setOutputKeyClass(Text.class);	<span class="comment">//设置输出类型</span></div><div class="line">				job.setOutputValueClass(IntWritable.class);	<span class="comment">//设置输出类型</span></div><div class="line">				FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));	<span class="comment">//设置输入文件</span></div><div class="line">				FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));	<span class="comment">//设置输出文件</span></div><div class="line">				</div><div class="line">				<span class="keyword">boolean</span> flag = job.waitForCompletion(<span class="keyword">true</span>);</div><div class="line">				System.out.println(<span class="string">"SUCCEED!"</span>+flag);	<span class="comment">//任务完成提示</span></div><div class="line">				System.exit(flag ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line">				System.out.println();</div><div class="line">				</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之后：<br>（1）在Eclipse设置输入/输出目录<br>（2）导出项目jar包，存储到工程目录下，即可提交任务 Run on Hadoop.</p>
<p>注意，使用Map/Reduce插件建立的项目在运行时控制台并没有日志输出，所以在上面的代码最后添加一行输出 <code>System.out.println(&quot;SUCCEED!&quot;+flag);</code>,当控制台最后输出<code>SUCCEED!true</code>时，表示任务运行成功，这是可以刷新 DFS Locations,会看到输出结果已经出来了。</p>
<p>本教程来自《Hadoop大数据处理技术基础与实战》–安俊秀 编著。</p>
<p>郑重声明：</p>
<p>在Windows下运行MapReduce程序，各种错误都有，如果有条件的话，建议在Linux下编程，Windows下实在麻烦。</p>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce之去重计数类应用</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/MapReduce%E4%B9%8B%E5%8E%BB%E9%87%8D%E8%AE%A1%E6%95%B0%E7%B1%BB%E5%BA%94%E7%94%A8/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/MapReduce之去重计数类应用/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:53:32.420Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="应用需求"><a href="#应用需求" class="headerlink" title="应用需求"></a>应用需求</h2><p>在大数据文件中包含了大量的记录，每条记录记载了某事物的一些属性，需要根据某几个属性的组合，去除相同的重复组合，并统计其中某属性的统计值。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>在此类应用中，将计算过程分为两个步骤。<br>第一步，map 函数将每条记录中需要关注的属性组合作为关键字，将空字符串作为值，生成的&lt;键-值&gt;对作为中间值输出。<br>第二步，reduce 函数则将输入的中间结果的 key 作为新的 key,value仍然取空字符串，输出结果。<br>因为所有相同的 key 都被送到同一个 reducer，而 reducer 只输出了一个 key，这一过程实际上就是去重的过程。</p>
<h2 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h2><p>以下两个文件，文件中表示某天，某IP访问了系统这样一个日志。当时间和IP相同时，将这种相同的数据去掉，只留一个。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">log1.txt:</div><div class="line">2014-10-3	10.3.5.19</div><div class="line">2014-10-3	10.3.3.19</div><div class="line">2014-10-3	10.3.5.18</div><div class="line">2014-10-3	10.3.51.19</div><div class="line">2014-10-3	10.3.2.19</div><div class="line">2014-10-4	10.3.2.5</div><div class="line">2014-10-4	10.3.2.18</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">log2.txt</div><div class="line">2014-10-3	10.3.5.19</div><div class="line">2014-10-4	10.3.5.19</div><div class="line">2014-10-3	10.3.5.18</div><div class="line">2014-10-5	10.3.51.19</div><div class="line">2014-10-4	10.3.2.5</div><div class="line">2014-10-5	10.3.2.19</div></pre></td></tr></table></figure>
<h2 id="程序代码"><a href="#程序代码" class="headerlink" title="程序代码"></a>程序代码</h2><h3 id="UniqMapper"><a href="#UniqMapper" class="headerlink" title="UniqMapper"></a>UniqMapper</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.uniq;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UniqMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		context.write(value, <span class="keyword">new</span> Text(<span class="string">""</span>));</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="UniqReducer"><a href="#UniqReducer" class="headerlink" title="UniqReducer"></a>UniqReducer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.uniq;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UniqReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		context.write(key, <span class="keyword">new</span> Text(<span class="string">""</span>));</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="UniqRunner"><a href="#UniqRunner" class="headerlink" title="UniqRunner"></a>UniqRunner</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.uniq;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UniqRunner</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span></span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		</div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		Job job = Job.getInstance(conf);</div><div class="line">		job.setJarByClass(UniqRunner.class);</div><div class="line">		</div><div class="line">		job.setMapperClass(UniqMapper.class);</div><div class="line">		job.setReducerClass(UniqReducer.class);</div><div class="line">		</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(Text.class);</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(Text.class);</div><div class="line">		</div><div class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">		</div><div class="line">		<span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span>:<span class="number">1</span>;</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		<span class="keyword">int</span> res = ToolRunner.run(<span class="keyword">new</span> Configuration(),<span class="keyword">new</span> UniqRunner(), args);</div><div class="line">		System.exit(res);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">2014-10-3	10.3.2.19	</div><div class="line">2014-10-3	10.3.3.19	</div><div class="line">2014-10-3	10.3.5.18	</div><div class="line">2014-10-3	10.3.5.19	</div><div class="line">2014-10-3	10.3.51.19	</div><div class="line">2014-10-4	10.3.2.18	</div><div class="line">2014-10-4	10.3.2.5	</div><div class="line">2014-10-4	10.3.5.19	</div><div class="line">2014-10-5	10.3.2.19	</div><div class="line">2014-10-5	10.3.51.19</div></pre></td></tr></table></figure></the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce之简单排序类应用</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/MapReduce%E4%B9%8B%E7%AE%80%E5%8D%95%E6%8E%92%E5%BA%8F%E7%B1%BB%E5%BA%94%E7%94%A8/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/MapReduce之简单排序类应用/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:53:20.180Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="应用需求"><a href="#应用需求" class="headerlink" title="应用需求"></a>应用需求</h2><p>通常在数据文件中包含大量的记录，每条记录中包含了这个事物的某个属性，需要根据这个属性对数据进行排序。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>map 函数对每条记录的事物和属性按照特定的规则进行计算，获得属性值，并以属性为 key,value为原数据值。reduce 函数对同组的排序值进行排序后按顺序输出。</p>
<h2 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h2><p>对输入文件中数据进行排序。输入文件中的每行内容均为一个数字，即一个数据。要求在输出中每行有两个间隔的数字，其中，第一个代表原始数据在数据集排序中的位次，第二个代表原始数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">sort1.txt:</div><div class="line">34</div><div class="line">6543</div><div class="line">12</div><div class="line">-45</div><div class="line">58</div><div class="line">753</div><div class="line">234</div><div class="line">858</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">sort2.txt:</div><div class="line">34</div><div class="line">675</div><div class="line">349</div><div class="line">648</div><div class="line">75</div><div class="line">39</div><div class="line">-7</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">sort3.txt:</div><div class="line">34</div><div class="line">76</div><div class="line">236</div><div class="line">2387</div><div class="line">-497</div><div class="line">45</div><div class="line">34</div></pre></td></tr></table></figure>
<h2 id="程序代码"><a href="#程序代码" class="headerlink" title="程序代码"></a>程序代码</h2><h3 id="SortMapper"><a href="#SortMapper" class="headerlink" title="SortMapper"></a>SortMapper</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.sort;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SortMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> IntWritable data = <span class="keyword">new</span> IntWritable();</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value,Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		String line = value.toString();</div><div class="line">		data.set(Integer.parseInt(line));</div><div class="line">		context.write(data, one);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="SortReducer"><a href="#SortReducer" class="headerlink" title="SortReducer"></a>SortReducer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.sort;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SortReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">IntWritable</span>, <span class="title">IntWritable</span>, <span class="title">IntWritable</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> IntWritable lineNum = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(IntWritable key, Iterable&lt;IntWritable&gt; values,Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		<span class="keyword">for</span> (IntWritable val : values) &#123;</div><div class="line">			context.write(lineNum, key);</div><div class="line">			lineNum = <span class="keyword">new</span> IntWritable(lineNum.get() + <span class="number">1</span>);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="SortRunner"><a href="#SortRunner" class="headerlink" title="SortRunner"></a>SortRunner</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.sort;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SortRunner</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span></span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		</div><div class="line">		Configuration  conf = <span class="keyword">new</span> Configuration();</div><div class="line">		Job job = Job.getInstance(conf, <span class="string">"Simple Sort"</span>);</div><div class="line">		job.setJarByClass(SortRunner.class);</div><div class="line">		</div><div class="line">		job.setMapperClass(SortMapper.class);</div><div class="line">		job.setReducerClass(SortReducer.class);</div><div class="line">		</div><div class="line">		job.setMapOutputKeyClass(IntWritable.class);</div><div class="line">		job.setMapOutputValueClass(IntWritable.class);</div><div class="line">		job.setOutputKeyClass(IntWritable.class);</div><div class="line">		job.setOutputValueClass(IntWritable.class);</div><div class="line">		</div><div class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">		</div><div class="line">		<span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span>:<span class="number">1</span>;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		<span class="keyword">int</span> res = ToolRunner.run(<span class="keyword">new</span> Configuration(), <span class="keyword">new</span> SortRunner(), args);</div><div class="line">		System.exit(res);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">1	-497</div><div class="line">2	-45</div><div class="line">3	-7</div><div class="line">4	12</div><div class="line">5	34</div><div class="line">6	34</div><div class="line">7	34</div><div class="line">8	34</div><div class="line">9	39</div><div class="line">10	45</div><div class="line">11	58</div><div class="line">12	75</div><div class="line">13	76</div><div class="line">14	234</div><div class="line">15	236</div><div class="line">16	349</div><div class="line">17	648</div><div class="line">18	675</div><div class="line">19	753</div><div class="line">20	858</div><div class="line">21	2387</div><div class="line">22	6543</div></pre></td></tr></table></figure>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce之连接操作类应用</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/MapReduce%E4%B9%8B%E8%BF%9E%E6%8E%A5%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%BA%94%E7%94%A8/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/MapReduce之连接操作类应用/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:53:26.349Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="用MapReduce实现关系的自然连接"><a href="#用MapReduce实现关系的自然连接" class="headerlink" title="用MapReduce实现关系的自然连接"></a>用MapReduce实现关系的自然连接</h2><center><img src="http://oni2hc3a8.bkt.clouddn.com/bigdatajoin.png" alt="join"></center>

<ul>
<li>假设有关系R(A，B)和S(B,C)，对二者进行自然连接操作</li>
<li>使用Map过程，把来自R的每个元组<code>&lt;a,b&gt;</code>转换成一个键值对<code>&lt;b, &lt;R,a&gt;&gt;</code>，其中的键就是属性B的值。把关系R包含到值中，这样做使得我们可以在Reduce阶段，只把那些来自R的元组和来自S的元组进行匹配。类似地，使用Map过程，把来自S的每个元组<code>&lt;b,c&gt;</code>，转换成一个键值对<code>&lt;b,&lt;S,c&gt;&gt;</code></li>
<li>所有具有相同B值的元组被发送到同一个Reduce进程中，Reduce进程的任务是，把来自关系R和S的、具有相同属性B值的元组进行合并</li>
<li>Reduce进程的输出则是连接后的元组<a,b,c>，输出被写到一个单独的输出文件中</a,b,c></li>
</ul>
<h2 id="自然连接过程"><a href="#自然连接过程" class="headerlink" title="自然连接过程"></a>自然连接过程</h2><center><img src="http://oni2hc3a8.bkt.clouddn.com/bigdatajoinProcess.png" alt="joinProcess"></center>


<h2 id="应用示例"><a href="#应用示例" class="headerlink" title="应用示例"></a>应用示例</h2><p>在HDFS中有两个文件，一个记录了学生的基本信息，包含了姓名和学号信息，名为student_info.txt,内容为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Jenny	00001</div><div class="line">Hardy	00002</div><div class="line">Bradley	00003</div></pre></td></tr></table></figure>
<p>还有一个文件记录了学生的选课信息表，包括了学号和课程名，名为student_class_info.txt,内容为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">00001	Chinese</div><div class="line">00001	Math</div><div class="line">00002	Music</div><div class="line">00002	Math</div><div class="line">00003	Physic</div></pre></td></tr></table></figure>
<p>现在经join操作后，得出的结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Jenny	Chinese</div><div class="line">Jenny	Math</div><div class="line">Hardy	Music</div><div class="line">Hardy	Math</div><div class="line">Bradley	Physic</div></pre></td></tr></table></figure>
<h2 id="程序代码"><a href="#程序代码" class="headerlink" title="程序代码"></a>程序代码</h2><h3 id="JoinMapper"><a href="#JoinMapper" class="headerlink" title="JoinMapper"></a>JoinMapper</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.join;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String STUDENT_FILENAME = <span class="string">"student_info.txt"</span>;</div><div class="line">	<span class="keyword">private</span>	<span class="keyword">static</span> <span class="keyword">final</span> String STUDENT_CLASS_FILENAME = <span class="string">"student_class_info.txt"</span>;</div><div class="line">	<span class="keyword">private</span>	<span class="keyword">static</span> <span class="keyword">final</span> String STUDENT_FLAG = <span class="string">"student"</span>;</div><div class="line">	<span class="keyword">private</span>	<span class="keyword">static</span> <span class="keyword">final</span> String STUDENT_CLASS_FLAG = <span class="string">"student_class"</span>;</div><div class="line">	</div><div class="line">	<span class="keyword">private</span> FileSplit fileSplit;</div><div class="line">	<span class="keyword">private</span> Text outKey = <span class="keyword">new</span> Text();</div><div class="line">	<span class="keyword">private</span> Text outValue = <span class="keyword">new</span> Text();</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		fileSplit = (FileSplit) context.getInputSplit();</div><div class="line">		String filePath = fileSplit.getPath().toString();</div><div class="line">		</div><div class="line">		String line = value.toString();</div><div class="line">		String[] fields = StringUtils.split(line,<span class="string">"\t"</span>);</div><div class="line">		</div><div class="line">		<span class="comment">//判断记录来自哪个文件</span></div><div class="line">		<span class="keyword">if</span> (filePath.contains(STUDENT_FILENAME)) &#123;</div><div class="line">			outKey.set(fields[<span class="number">1</span>]);</div><div class="line">			outValue.set(STUDENT_FLAG + <span class="string">"\t"</span> + fields[<span class="number">0</span>]);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> <span class="keyword">if</span> (filePath.contains(STUDENT_CLASS_FILENAME)) &#123;</div><div class="line">			outKey.set(fields[<span class="number">0</span>]);</div><div class="line">			outValue.set(STUDENT_CLASS_FLAG + <span class="string">"\t"</span> + fields[<span class="number">1</span>]);</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		context.write(outKey, outValue);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="JoinReducer"><a href="#JoinReducer" class="headerlink" title="JoinReducer"></a>JoinReducer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.join;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.ArrayList;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line">	<span class="keyword">private</span>	<span class="keyword">static</span> <span class="keyword">final</span> String STUDENT_FLAG = <span class="string">"student"</span>;</div><div class="line">	<span class="keyword">private</span>	<span class="keyword">static</span> <span class="keyword">final</span> String STUDENT_CLASS_FLAG = <span class="string">"student_class"</span>;</div><div class="line">	</div><div class="line">	<span class="keyword">private</span> String fileFlag = <span class="keyword">null</span>;</div><div class="line">	<span class="keyword">private</span> String stuName = <span class="keyword">null</span>;</div><div class="line">	<span class="keyword">private</span> List&lt;String&gt; stuClassNames;</div><div class="line">	</div><div class="line">	<span class="keyword">private</span> Text outKey = <span class="keyword">new</span> Text();</div><div class="line">	<span class="keyword">private</span> Text outValue = <span class="keyword">new</span> Text();</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		stuClassNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">		</div><div class="line">		<span class="keyword">for</span> (Text val : values) &#123;</div><div class="line">			String[] fields = StringUtils.split(val.toString(),<span class="string">"\t"</span>);</div><div class="line">			fileFlag = fields[<span class="number">0</span>];</div><div class="line">			<span class="comment">//判断记录来自哪个文件，并根据文件格式解析记录。</span></div><div class="line">			<span class="keyword">if</span> (fileFlag.equals(STUDENT_FLAG)) &#123;</div><div class="line">				stuName = fields[<span class="number">1</span>];</div><div class="line">				outKey.set(stuName);</div><div class="line">			&#125;</div><div class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (fileFlag.equals(STUDENT_CLASS_FLAG)) &#123;</div><div class="line">				stuClassNames.add(fields[<span class="number">1</span>]);</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		<span class="comment">//求笛卡尔积</span></div><div class="line">		<span class="keyword">for</span> (String stuClassName : stuClassNames) &#123;</div><div class="line">			outValue.set(stuClassName);</div><div class="line">			context.write(outKey, outValue);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="JoinRunner"><a href="#JoinRunner" class="headerlink" title="JoinRunner"></a>JoinRunner</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.join;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinRunner</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span></span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		Job job = Job.getInstance(conf, <span class="string">"Join"</span>);</div><div class="line">		job.setJarByClass(JoinRunner.class);</div><div class="line">		</div><div class="line">		job.setMapperClass(JoinMapper.class);</div><div class="line">		job.setReducerClass(JoinReducer.class);</div><div class="line">		</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(Text.class);</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(Text.class);</div><div class="line">		</div><div class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">		</div><div class="line">		<span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span>:<span class="number">1</span>;</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		<span class="keyword">int</span> res = ToolRunner.run(<span class="keyword">new</span> Configuration(), <span class="keyword">new</span> JoinRunner(), args);</div><div class="line">		System.exit(res);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Jenny	Math</div><div class="line">Jenny	Chinese</div><div class="line">Hardy	Math</div><div class="line">Hardy	Music</div><div class="line">Bradley	Physic</div></pre></td></tr></table></figure>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce之计数类应用</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/MapReduce%E4%B9%8B%E8%AE%A1%E6%95%B0%E7%B1%BB%E5%BA%94%E7%94%A8/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/MapReduce之计数类应用/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:53:10.468Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="应用需求"><a href="#应用需求" class="headerlink" title="应用需求"></a>应用需求</h2><p>在数据文件中包含大量的记录，每条记录中包含某类事物的若干属性，在实际应用中需要根据这类事物的某个属性进行数值计算，如求和、平均值等。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>针对这类应用，在 Map 函数中提取每条记录中这类事物的特定属性值，在 Reduce 函数中对所有相同事物属性值按照函数表达式进行计算。</p>
<h2 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h2><p>WordCount 就是经典的计数类应用中求和案例，下面通过另一案例讲解求平均值的方法。现在一个班级有 Rose、Andy、Tom、John、Michelle、Amy、Kim等同学，学习了 English、Math、Chinese 三门课程，一门课程是一个文本文件，通过运算求每个同学的平均成绩。文件内容如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">English.txt:		</div><div class="line">Rose		91	</div><div class="line">Andy		87</div><div class="line">Tom		 78</div><div class="line">John		94</div><div class="line">Michelle	74</div><div class="line">Amy		 67</div><div class="line">Kim		 71</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Math.txt:		</div><div class="line">Rose		83	</div><div class="line">Andy		93</div><div class="line">Tom		 67</div><div class="line">John		92</div><div class="line">Michelle	82</div><div class="line">Amy		 85</div><div class="line">Kim		 80</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Chinese.txt:		</div><div class="line">Rose		85	</div><div class="line">Andy		84</div><div class="line">Tom		 85</div><div class="line">John		77</div><div class="line">Michelle	93</div><div class="line">Amy		 94</div><div class="line">Kim		 83</div></pre></td></tr></table></figure>
<h2 id="程序代码"><a href="#程序代码" class="headerlink" title="程序代码"></a>程序代码</h2><h3 id="AverageMapper"><a href="#AverageMapper" class="headerlink" title="AverageMapper"></a>AverageMapper</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.score;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.StringTokenizer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AverageMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="keyword">private</span> Text name = <span class="keyword">new</span> Text();</div><div class="line">	<span class="keyword">private</span> IntWritable score = <span class="keyword">new</span> IntWritable();</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		String line = value.toString();</div><div class="line">		StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(line);</div><div class="line">		<span class="keyword">while</span>(itr.hasMoreTokens())&#123;</div><div class="line">			name.set(itr.nextToken());</div><div class="line">			score.set(Integer.parseInt(itr.nextToken()));</div><div class="line">			context.write(name, score);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="AverageReducer"><a href="#AverageReducer" class="headerlink" title="AverageReducer"></a>AverageReducer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.score;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AverageReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		<span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">		<span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (IntWritable val : values) &#123;</div><div class="line">			sum += val.get();</div><div class="line">			++count;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">int</span> avg = sum / count;</div><div class="line">		context.write(key, <span class="keyword">new</span> IntWritable(avg));</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="AverageRunner"><a href="#AverageRunner" class="headerlink" title="AverageRunner"></a>AverageRunner</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.score;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AverageRunner</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span></span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		Job job = Job.getInstance(conf);</div><div class="line">		job.setJarByClass(AverageRunner.class);</div><div class="line">		</div><div class="line">		job.setMapperClass(AverageMapper.class);</div><div class="line">		job.setReducerClass(AverageReducer.class);</div><div class="line">		</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(IntWritable.class);</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(IntWritable.class);</div><div class="line">		</div><div class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">		</div><div class="line">		<span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span>:<span class="number">1</span>;</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		<span class="keyword">int</span> res = ToolRunner.run(<span class="keyword">new</span> Configuration(), <span class="keyword">new</span> AverageRunner(), args);</div><div class="line">		System.exit(res);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Amy	82</div><div class="line">Andy	88</div><div class="line">John	87</div><div class="line">Kim	78</div><div class="line">Michelle	83</div><div class="line">Rose	86</div><div class="line">Tom	76</div></pre></td></tr></table></figure>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce之二次排序类应用</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/MapReduce%E4%B9%8B%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E7%B1%BB%E5%BA%94%E7%94%A8/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/MapReduce之二次排序类应用/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:53:04.357Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="应用需求"><a href="#应用需求" class="headerlink" title="应用需求"></a>应用需求</h2><p>在某些应用场合中，需要对数据文件中的大量记录某个属性进行排序，可是这个属性的记录太多，需要根据其他属性在排序。这种应用称为“二次排序”。</p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>在对大数据进行分析时，常采用排序的方式，排序后，发现数据量太大，具有相同关键值的记录也非常多，这是，就需要对第二属性进行排序。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>默认情况下，Map 输出的结果会对 Key 进行默认排序，但是“二次排序”中除了对 Key 进行排序外，还需要对位于 value 值中的另外一个属性进行排序，而 MapReduce 框架并没有提供对 value 值进行排序的方法。怎么实现对 value 的排序呢？ 这就需要变通的去实现这个需求。</p>
<p>变通手段：</p>
<p>可以把 key 和 value 联合起来作为新的 Key,记作 Newkey。这时，NewKey含有两个字段，假设分别为k,v.这里的k和v是原来的 key 和 value。原来的value还是不变。这样，value就同时在NewKey和value的位置。再实现NewKey的比较规则，先按照key排序，在key相同的基础上再按照value排序。在分组时，在按照原来的key进行分组，就不会影响原有的分组逻辑了。最后在输出时，只把原有的key、value输出，就可以变通的实现了二次排序的需求。</p>
<h2 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h2><p>现有一输入文件，包含两列数据，要求先按照第一列整数大小排序，如果第一列相同，按照第二列整数大小排序。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">secondrysort.txt:</div><div class="line">20 21		70 56		60 56</div><div class="line">50 51		70 57		60 57</div><div class="line">50 52		70 58		740 58</div><div class="line">50 53		5  6		63 61</div><div class="line">50 54		7  82		730 54</div><div class="line">60 51		203 21		71 55</div><div class="line">60 53		50 512		71 56</div><div class="line">60 52		50 522		73 57</div><div class="line">60 56		50 53		74 58</div><div class="line">60 57		530 54		12 211</div><div class="line">70 58		40 511		31 42</div><div class="line">60 61		20 53		50 62</div><div class="line">70 54		20 522		7  8</div><div class="line">70 55</div></pre></td></tr></table></figure>
<h2 id="程序代码"><a href="#程序代码" class="headerlink" title="程序代码"></a>程序代码</h2><h3 id="SecondrySortPair"><a href="#SecondrySortPair" class="headerlink" title="SecondrySortPair"></a>SecondrySortPair</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.secondrysort;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.DataInput;</div><div class="line"><span class="keyword">import</span> java.io.DataOutput;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * 创建主键类 SecondrySortPair,把第一列整数和第二列整数作为类的属性。</div><div class="line"> * <span class="doctag">@author</span> hadoop</div><div class="line"> *</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecondrySortPair</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">SecondrySortPair</span>&gt;</span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">int</span> first = <span class="number">0</span>;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">int</span> second = <span class="number">0</span>;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(<span class="keyword">int</span> first, <span class="keyword">int</span> second)</span> </span>&#123;</div><div class="line">		<span class="keyword">this</span>.first = first;</div><div class="line">		<span class="keyword">this</span>.second = second;</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getFirst</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> first;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSecond</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> second;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">		first = in.readInt();</div><div class="line">		second = in.readInt();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">		out.writeInt(first);</div><div class="line">		out.writeInt(second);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">//这里的代码是关键，因为对key排序时，调用的就是这个compareTo方法</span></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(SecondrySortPair o)</span> </span>&#123;</div><div class="line">		<span class="keyword">if</span> (first != o.first) &#123;</div><div class="line">			<span class="keyword">return</span> first - o.first;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> <span class="keyword">if</span> (second != o.second) &#123;</div><div class="line">			<span class="keyword">return</span> second - o.second;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> &#123;</div><div class="line">			<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object obj)</span> </span>&#123;</div><div class="line">		<span class="keyword">if</span> (obj <span class="keyword">instanceof</span> SecondrySortPair) &#123;</div><div class="line">			SecondrySortPair o = (SecondrySortPair) obj;</div><div class="line">			<span class="keyword">return</span> first == o.first &amp;&amp; second == o.second;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> &#123;</div><div class="line">			<span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> first + <span class="string">""</span>.hashCode() + second + <span class="string">""</span>.hashCode();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="GroupingComparator"><a href="#GroupingComparator" class="headerlink" title="GroupingComparator"></a>GroupingComparator</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.secondrysort;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.RawComparator;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * 在分组比较时，只比较原来的key,而不是组合key</div><div class="line"> * <span class="doctag">@author</span> hadoop</div><div class="line"> *</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GroupingComparator</span> <span class="keyword">implements</span> <span class="title">RawComparator</span>&lt;<span class="title">SecondrySortPair</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(SecondrySortPair o1, SecondrySortPair o2)</span> </span>&#123;</div><div class="line">		<span class="keyword">int</span> first1 = o1.getFirst();</div><div class="line">		<span class="keyword">int</span> first2 = o2.getFirst();</div><div class="line">		<span class="keyword">return</span> first1 - first2;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(<span class="keyword">byte</span>[] b1, <span class="keyword">int</span> s1, <span class="keyword">int</span> l1, <span class="keyword">byte</span>[] b2, <span class="keyword">int</span> s2, <span class="keyword">int</span> l2)</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> WritableComparator.compareBytes(b1, s1, Integer.SIZE/<span class="number">8</span>, b2, s2, Integer.SIZE/<span class="number">8</span>);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="SecondarySortMapper"><a href="#SecondarySortMapper" class="headerlink" title="SecondarySortMapper"></a>SecondarySortMapper</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.secondrysort;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.StringTokenizer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecondrySortMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">SecondrySortPair</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">	<span class="keyword">private</span> SecondrySortPair newKey = <span class="keyword">new</span> SecondrySortPair();</div><div class="line">	<span class="keyword">private</span> IntWritable outValue = <span class="keyword">new</span> IntWritable();</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		<span class="keyword">int</span> first = <span class="number">0</span>, second = <span class="number">0</span>;</div><div class="line">		String line = value.toString();</div><div class="line">		StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(line);</div><div class="line">		<span class="keyword">while</span>(itr.hasMoreTokens())&#123;</div><div class="line">			first = Integer.parseInt(itr.nextToken());</div><div class="line">			<span class="keyword">if</span> (itr.hasMoreTokens()) &#123;</div><div class="line">				second = Integer.parseInt(itr.nextToken());</div><div class="line">			&#125;</div><div class="line">			newKey.set(first, second);</div><div class="line">			outValue.set(second);</div><div class="line">			context.write(newKey, outValue);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="SecondarySortReducer"><a href="#SecondarySortReducer" class="headerlink" title="SecondarySortReducer"></a>SecondarySortReducer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.secondrysort;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecondrySortReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">SecondrySortPair</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Text SEPARATOR = <span class="keyword">new</span> Text(<span class="string">"----------"</span>);</div><div class="line">	<span class="keyword">private</span> Text outKey = <span class="keyword">new</span> Text();</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(SecondrySortPair key, Iterable&lt;IntWritable&gt; values, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		context.write(SEPARATOR, <span class="keyword">null</span>);</div><div class="line">		outKey.set(Integer.toString(key.getFirst()));</div><div class="line">		<span class="keyword">for</span> (IntWritable val : values) &#123;</div><div class="line">			context.write(outKey, val);</div><div class="line">		&#125;</div><div class="line">	&#125;	</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="SecondarySortRunner"><a href="#SecondarySortRunner" class="headerlink" title="SecondarySortRunner"></a>SecondarySortRunner</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.secondrysort;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SecondrySortRunner</span> <span class="keyword">extends</span> <span class="title">Configured</span> <span class="keyword">implements</span> <span class="title">Tool</span></span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		Job job = Job.getInstance(conf, <span class="string">"SecondrySort"</span>);</div><div class="line">		job.setJarByClass(SecondrySortRunner.class);</div><div class="line">		</div><div class="line">		job.setMapperClass(SecondrySortMapper.class);</div><div class="line">		job.setReducerClass(SecondrySortReducer.class);</div><div class="line">		</div><div class="line">		<span class="comment">//设置分组函数类，对二次排序非常关键。</span></div><div class="line">		job.setGroupingComparatorClass(GroupingComparator.class);</div><div class="line">		</div><div class="line">		<span class="comment">//设置Map的输出 key value类，对二次排序非常重要。</span></div><div class="line">		job.setMapOutputKeyClass(SecondrySortPair.class);</div><div class="line">		job.setMapOutputValueClass(IntWritable.class);</div><div class="line">		</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(IntWritable.class);</div><div class="line">		</div><div class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">		</div><div class="line">		<span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span>:<span class="number">1</span>;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		<span class="keyword">int</span> res = ToolRunner.run(<span class="keyword">new</span> Configuration(), <span class="keyword">new</span> SecondrySortRunner(), args);</div><div class="line">		System.exit(res);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">----------</div><div class="line">5	6</div><div class="line">----------</div><div class="line">7	8</div><div class="line">7	82</div><div class="line">----------</div><div class="line">12	211</div><div class="line">----------</div><div class="line">20	21</div><div class="line">20	53</div><div class="line">20	522</div><div class="line">----------</div><div class="line">31	42</div><div class="line">----------</div><div class="line">40	511</div><div class="line">----------</div><div class="line">50	51</div><div class="line">50	52</div><div class="line">50	53</div><div class="line">50	53</div><div class="line">50	54</div><div class="line">50	62</div><div class="line">50	512</div><div class="line">50	522</div><div class="line">----------</div><div class="line">60	51</div><div class="line">60	52</div><div class="line">60	53</div><div class="line">60	56</div><div class="line">60	56</div><div class="line">60	57</div><div class="line">60	57</div><div class="line">60	61</div><div class="line">----------</div><div class="line">63	61</div><div class="line">----------</div><div class="line">70	54</div><div class="line">70	55</div><div class="line">70	56</div><div class="line">70	57</div><div class="line">70	58</div><div class="line">70	58</div><div class="line">----------</div><div class="line">71	55</div><div class="line">71	56</div><div class="line">----------</div><div class="line">73	57</div><div class="line">----------</div><div class="line">74	58</div><div class="line">----------</div><div class="line">203	21</div><div class="line">----------</div><div class="line">530	54</div><div class="line">----------</div><div class="line">730	54</div><div class="line">----------</div><div class="line">740	58</div></pre></td></tr></table></figure>
<h2 id="程序分析"><a href="#程序分析" class="headerlink" title="程序分析"></a>程序分析</h2><p>先对现在第一列和第二列整数创建一个新的类，作为NewKey，这里的NewKey类型为SecondrySortPair,对NewKey的比较有两种方法。</p>
<ul>
<li>在Map阶段的最后，会先调用job.setPartitionerClass 对输出的List进行分区，每个分区映射到一个Reducer，每个分区又调用job.setSortComparatorClass设置Key比较函数类进行排序。</li>
<li>如果没有通过job.setSortComparatorClass设置Key比较类，则使用Key实现的 compareTo方法排序，本例代码就使用了 compareTo方法排序。</li>
</ul>
<p>在Reduce阶段，Reduce接收到所有映射到这个Reduce的Map输出后，也会调用job.setSortComparatorClass设置的Key比较函数类对所有数据进行排序。<font color="red"><strong>然后开始构建一个Key对应的Value迭代器。这是就要用到分组，使用job.setGroupingComparatorClass设置的分组函数。只要这个比较器比较的两个Key相同，它们就属于同一个组，它们的Value就在一个Value迭代器</strong></font>，而这个迭代器的Key使用属于同一组的所有Key的第一个Key。</p>
<p>最后就是进入Reducer的reduce方法，reduce方法的输入是所有的Key和它的Value迭代器。</p>
<h2 id="不添加分组的结果"><a href="#不添加分组的结果" class="headerlink" title="不添加分组的结果"></a>不添加分组的结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div></pre></td><td class="code"><pre><div class="line">----------</div><div class="line">5	6</div><div class="line">----------</div><div class="line">7	8</div><div class="line">----------</div><div class="line">7	82</div><div class="line">----------</div><div class="line">12	211</div><div class="line">----------</div><div class="line">20	21</div><div class="line">----------</div><div class="line">20	53</div><div class="line">----------</div><div class="line">20	522</div><div class="line">----------</div><div class="line">31	42</div><div class="line">----------</div><div class="line">40	511</div><div class="line">----------</div><div class="line">50	51</div><div class="line">----------</div><div class="line">50	52</div><div class="line">----------</div><div class="line">50	53</div><div class="line">50	53</div><div class="line">----------</div><div class="line">50	54</div><div class="line">----------</div><div class="line">50	62</div><div class="line">----------</div><div class="line">50	512</div><div class="line">----------</div><div class="line">50	522</div><div class="line">----------</div><div class="line">60	51</div><div class="line">----------</div><div class="line">60	52</div><div class="line">----------</div><div class="line">60	53</div><div class="line">----------</div><div class="line">60	56</div><div class="line">60	56</div><div class="line">----------</div><div class="line">60	57</div><div class="line">60	57</div><div class="line">----------</div><div class="line">60	61</div><div class="line">----------</div><div class="line">63	61</div><div class="line">----------</div><div class="line">70	54</div><div class="line">----------</div><div class="line">70	55</div><div class="line">----------</div><div class="line">70	56</div><div class="line">----------</div><div class="line">70	57</div><div class="line">----------</div><div class="line">70	58</div><div class="line">70	58</div><div class="line">----------</div><div class="line">71	55</div><div class="line">----------</div><div class="line">71	56</div><div class="line">----------</div><div class="line">73	57</div><div class="line">----------</div><div class="line">74	58</div><div class="line">----------</div><div class="line">203	21</div><div class="line">----------</div><div class="line">530	54</div><div class="line">----------</div><div class="line">730	54</div><div class="line">----------</div><div class="line">740	58</div></pre></td></tr></table></figure>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce之倒排索引类应用</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/MapReduce%E4%B9%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%BA%94%E7%94%A8/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/MapReduce之倒排索引类应用/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:54:10.059Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="应用需求"><a href="#应用需求" class="headerlink" title="应用需求"></a>应用需求</h2><p>通常在数据文件中包含大量的单词，每个单词可能会出现多次，需要根据单词查找文档，这时就需要用到倒排索引。</p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>在全文检索系统或搜索引擎中，经常会用到根据单词查找文档。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>通常在 Map 过程中，对文档进行切分，把单词和文档URL设置为 Key，单词为文档中的次数为 Value，使用 Combine 函数对文档中的词频进行统计，然后将 单词作为 Key，文档URL和词频作为 Value 输出到 Reduce 中，Reduce 函数以单词为 Key，生成倒排索引。</p>
<h2 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h2><p>倒排索引主要是用来存储某个单词（或词组）在一个文档或一组文档中的存储位置的映射，即提供一种根据内容来查找文档的方式。由于不是根据文档来确定文档所包含的内容，而是进行相反操作，因而成为倒排索引。</p>
<p>通常情况下，倒排索引由一个单词（或词组）以及相关的文档列表组成，文档列表中的文档或者是表示文档的ID号，或者是指文档所在位置的URL。在实际应用中文档通常带有权重，即记录单词在文档中出现的次数。如下面所示。<br>有下面三个文档：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">D0.txt:</div><div class="line">MapReduce is simple is easy</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">D1.txt:</div><div class="line">MapReduce is powerful is userful</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">D2.txt:</div><div class="line">Hello MapReduce Bye MapReduce</div></pre></td></tr></table></figure>
<p>则 D0.txt、D1.txt和 D2.txt的倒排索引文件，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Bye	D2.txt:1;</div><div class="line">Hello	D2.txt:1;</div><div class="line">MapReduce	D2.txt:2;D1.txt:1;D0.txt:1;</div><div class="line">easy	D0.txt:1;</div><div class="line">is	D0.txt:2;D1.txt:2;</div><div class="line">powerful	D1.txt:1;</div><div class="line">simple	D0.txt:1;</div><div class="line">userful	D1.txt:1;</div></pre></td></tr></table></figure>
<p>如上面倒排索引所示，倒排索引文件中的 MapReduce 一行表示：MapReduce 这个单词在文本D0中出现1次，D1中出现1次，D2中出现2次。<br>当搜索条件为 MapReduce、is、Simple时，对应的集合为：{D0,D1,D2} &amp;&amp; {D0,D1} &amp;&amp; {D0} = {D0}，即文档 D0 包含了所要索引的单词，而且是连续的。</p>
<p>在实际的搜索引擎应用中，除了考虑词频外，还要考虑单词出现的位置，比如单词出现在标题和 URL 中就比出现在正文中的权重高。</p>
<h2 id="分析与设计"><a href="#分析与设计" class="headerlink" title="分析与设计"></a>分析与设计</h2><h3 id="Map过程"><a href="#Map过程" class="headerlink" title="Map过程"></a>Map过程</h3><p>首先使用默认的TextInputFormat类对输入文件进行处理，得到文本中每行的偏移量及其内容，Map过程首先必须分析输入的<key, value="">对，得到倒排索引中需要的三个信息：单词、文档URI和词频，如图所示：</key,></p>
<center><img src="http://oni2hc3a8.bkt.clouddn.com/bigdataInvertIndexMapper.jpg" alt="InvertedIndexMapper"></center>

<p>存在两个问题，第一：<key, value="">对只能有两个值，在不使用Hadoop自定义数据类型的情况下，需要根据情况将其中的两个值合并成一个值，作为value或key值；</key,></p>
<p>第二，通过一个Reduce过程无法同时完成词频统计和生成文档列表，所以必须增加一个Combine过程完成词频统计.</p>
<p>这里将单词和文档URL组成 Key 值（如 MapReduce:D0.txt）,将词频作为 Value，这样做的目的是可以将同一文档的相同单词的词频组成列表，传递给 Combine 过程，就可以计算同一文档中单词的词频。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.invertedindex;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.StringTokenizer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InvertedIndexMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="keyword">private</span> Text keyInfo = <span class="keyword">new</span> Text();	<span class="comment">//存储单词和文档URL组合</span></div><div class="line">	<span class="keyword">private</span> Text valueInfo = <span class="keyword">new</span> Text();	<span class="comment">//存储词频</span></div><div class="line">	<span class="keyword">private</span> FileSplit fileSplit;	<span class="comment">//存储 FileSplit对象，目的为获取文档URL</span></div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		<span class="comment">//获取单词所属的 FileSplit 对象。</span></div><div class="line">		fileSplit = (FileSplit) context.getInputSplit();</div><div class="line">		</div><div class="line">		String line = value.toString();</div><div class="line">		StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(line);</div><div class="line">		<span class="keyword">while</span>(itr.hasMoreTokens())&#123;</div><div class="line">			<span class="comment">//获取文件完整路径</span></div><div class="line">			<span class="comment">//keyInfo.set(itr.nextToken() + ":" + fileSplit.getPath().toString());</span></div><div class="line">			<span class="comment">//这里只获取文件的名称</span></div><div class="line">			<span class="keyword">int</span> splitIndex = fileSplit.getPath().toString().indexOf(<span class="string">"D"</span>);</div><div class="line">			<span class="comment">//key值由单词和文档URL组成，如 "MapReduce:D0.txt"</span></div><div class="line">			keyInfo.set(itr.nextToken() + <span class="string">":"</span> + fileSplit.getPath().toString().substring(splitIndex));</div><div class="line">			</div><div class="line">			<span class="comment">//词频初始化为1</span></div><div class="line">			valueInfo.set(<span class="string">"1"</span>);</div><div class="line">			</div><div class="line">			context.write(keyInfo, valueInfo);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Combine-过程"><a href="#Combine-过程" class="headerlink" title="Combine 过程"></a>Combine 过程</h3><p>经过 Map 方法处理后，Combine过程将key值相同的value值累加，得到一个单词在文档中的词频，如图。</p>
<center><img src="http://oni2hc3a8.bkt.clouddn.com/bigdataInvertedIndexCombiner.jpg" alt="InvertedIndexCombiner"></center>

<p>如果直接将上图所示的输出作为Reduce过程的输入，在Shuffle过程将面临一个问题：所有具有相同单词的记录（由单词、文档URL和词频组成）应该交由同一个Reducer处理，但当前的Key值无法保证这一点，所以必须修改Key值和Value值。这次将单词作为Key值，文档URL和词频组成Value值（如 D0.txt:1）.这样做的好处是可以利用MapReduce框架默认的HashPartitioner类完成Shuffle过程，将相同单词的所有记录发送给同一个Reducer进行处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.invertedindex;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="comment">//计算每个单词所在文档的词频</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InvertedIndexCombiner</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt;</span>&#123;</div><div class="line"></div><div class="line">	<span class="keyword">private</span> Text info = <span class="keyword">new</span> Text();</div><div class="line">	</div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span></span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		<span class="comment">//统计词频</span></div><div class="line">		<span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (Text val : values) &#123;</div><div class="line">			sum += Integer.parseInt(val.toString());</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		<span class="keyword">int</span> splitIndex = key.toString().indexOf(<span class="string">":"</span>);</div><div class="line">		</div><div class="line">		<span class="comment">//重新设置 value 的值为文档URL和词频组成。</span></div><div class="line">		info.set(key.toString().substring(splitIndex + <span class="number">1</span>) + <span class="string">":"</span> + sum);</div><div class="line">		<span class="comment">//重新设置 key 的值为单词</span></div><div class="line">		key.set(key.toString().substring(<span class="number">0</span>, splitIndex));</div><div class="line">		</div><div class="line">		</div><div class="line">		context.write(key, info);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="Reduce-过程"><a href="#Reduce-过程" class="headerlink" title="Reduce 过程"></a>Reduce 过程</h3><p>经过上述两个过程后，Reduce过程只需将相同key值的value值组合成倒排索引文件所需的格式即可，剩下的事情就可以直接交给MapReduce框架进行处理。如图。</p>
<center><img src="http://oni2hc3a8.bkt.clouddn.com/bigdataInvertedIndexReducer.jpg" alt="InvertedIndexReducer"></center>


</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>HDFS Java API</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/HDFS%20Java%20API/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/HDFS Java API/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:54:14.026Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">


<ul>
<li>通常MapReduce会把一个文件数据块处理成一个Map任务。</li>
<li>HDFS默认工作目录为/user/${USER},${USER}是当前的登录用户名。</li>
</ul>
<h2 id="HDFS中的-Java-API-的使用"><a href="#HDFS中的-Java-API-的使用" class="headerlink" title="HDFS中的 Java API 的使用"></a>HDFS中的 Java API 的使用</h2><ul>
<li>文件在 Hadoop 中表示一个Path对象，通常封装一个URI，如HDFS上有个test文件，URI表示成hdfs://master:9000/test。</li>
<li>Hadoop 中关于文件操作类基本上全部是在”org.apache.hadoop.fs”包中，这些 API 能够支持的操作包含打开文件、读写文件、删除文件等。</li>
</ul>
<p>Hadoop 类库中最终面向用户提供的接口类是 FileSystem，该类是个抽象类，只能通过类的 get 方法得到具体的类。get 方法存在几个重载版本，常用的是 static FileSystem get(Configuration conf); 该类封装了几乎所有的文件操作，如 mkdir、delete等。综上基本上可以得出操作文件的程序库框架：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">operator()</div><div class="line">&#123;</div><div class="line">	得到Configuration对象</div><div class="line">	得到FileSystem对象</div><div class="line">	进行文件操作</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h3><p>通过 “FileSystem.copyFromLocalFile(Path src,Path dst)” 可将本地文件上传到HDFS指定的位置上，其中 src 和 dst 均为文件完整路径，具体示例如下。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.hdfs;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"><span class="keyword">import</span> java.net.URISyntaxException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"></div><div class="line"><span class="comment">//文件上传至HDFS</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PutFile</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> URISyntaxException, IOException </span>&#123;</div><div class="line">		<span class="comment">// TODO Auto-generated method stub</span></div><div class="line">		Configuration con = <span class="keyword">new</span> Configuration();</div><div class="line">		</div><div class="line">		URI uri = <span class="keyword">new</span> URI(<span class="string">"hdfs://master:9000"</span>);</div><div class="line">		FileSystem fs = FileSystem.get(uri, con);</div><div class="line"></div><div class="line">		<span class="comment">//本地文件</span></div><div class="line">		Path src = <span class="keyword">new</span> Path(<span class="string">"D:\\test.txt"</span>);</div><div class="line">		<span class="comment">//HDFS存放文件</span></div><div class="line">		Path dst = <span class="keyword">new</span> Path(<span class="string">"/"</span>);</div><div class="line">		<span class="comment">//上传文件</span></div><div class="line">		fs.copyFromLocalFile(src, dst);</div><div class="line">		System.out.println(<span class="string">"Upload to "</span>+con.get(<span class="string">"fs.defaultFS"</span>));</div><div class="line">                                   </div><div class="line">		<span class="comment">//以下相当于执行hdfs dfs -ls /</span></div><div class="line">		FileStatus[] files = fs.listStatus(dst);</div><div class="line">		<span class="keyword">for</span> (FileStatus file : files) &#123;</div><div class="line">			System.out.println(file.getPath());</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="新建文件"><a href="#新建文件" class="headerlink" title="新建文件"></a>新建文件</h3><p>通过 “FileSystem.create(Path f, Boolean b)” 可在 HDFS 上创建文件，其中 f 为文件的完整路径， b 为判断是否覆盖，具体实现如下。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.hdfs;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"><span class="keyword">import</span> java.net.URISyntaxException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CreateFile</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> URISyntaxException, IOException </span>&#123;</div><div class="line">		<span class="comment">// TODO Auto-generated method stub</span></div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		URI uri = <span class="keyword">new</span> URI(<span class="string">"hdfs://master:9000"</span>);</div><div class="line">		FileSystem fs = FileSystem.get(uri, conf);</div><div class="line">		</div><div class="line">		<span class="comment">//定义新文件</span></div><div class="line">		Path dfs = <span class="keyword">new</span> Path(<span class="string">"/hdfsfile"</span>);</div><div class="line">		<span class="comment">//创建新文件，如果有则覆盖（true）</span></div><div class="line">		FSDataOutputStream create = fs.create(dfs, <span class="keyword">true</span>);</div><div class="line">		<span class="comment">//创建目录为：fs.mkdirs()</span></div><div class="line"></div><div class="line">		<span class="comment">//向新创建的文件中写入数据</span></div><div class="line">		create.writeBytes(<span class="string">"Hello,HDFS!"</span>);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="查看文件详细信息"><a href="#查看文件详细信息" class="headerlink" title="查看文件详细信息"></a>查看文件详细信息</h3><p>通过 “Class FileStatus” 可查找指定文件在 HDFS 集群上的具体信息，包括文件路径、访问时间、修改时间、文件长度、所占块大小、文件拥有者、文件用户组和文件复制数等信息，具体实现如下。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.hdfs;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"><span class="keyword">import</span> java.net.URISyntaxException;</div><div class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.BlockLocation;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileLocation</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> URISyntaxException, IOException </span>&#123;</div><div class="line">		<span class="comment">// TODO Auto-generated method stub</span></div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		URI uri = <span class="keyword">new</span> URI(<span class="string">"hdfs://master:9000"</span>);</div><div class="line">		FileSystem fs = FileSystem.get(uri, conf);</div><div class="line">		</div><div class="line">		Path fPath = <span class="keyword">new</span> Path(<span class="string">"/hdfsfile"</span>);</div><div class="line">		FileStatus fileStatus = fs.getFileStatus(fPath);</div><div class="line">		</div><div class="line">		<span class="comment">/*获取文件在  HDFS 集群位置</span></div><div class="line">		 *FileSystem.getFileBlockLocations(FileStatus file, long start, long len)</div><div class="line">		 *可查找指定文件在 HDFS 集群上的位置 ，其中 file 为文件的完整路径， start 和 len 来标识查找文件的路径</div><div class="line">		 * */</div><div class="line">		BlockLocation[] blockLocations = fs.getFileBlockLocations(fileStatus, <span class="number">0</span>, </div><div class="line">				fileStatus.getLen());</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; blockLocations.length; i++) &#123;</div><div class="line">			String[] hosts = blockLocations[i].getHosts();</div><div class="line">			System.out.println(<span class="string">"block_"</span>+i+<span class="string">"_location:"</span>+hosts[<span class="number">0</span>]);</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		<span class="comment">//格式化日期输出</span></div><div class="line">		SimpleDateFormat formatter = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>);</div><div class="line">		</div><div class="line">		<span class="comment">//获取文件访问时间，返回long</span></div><div class="line">		<span class="keyword">long</span> accessTime = fileStatus.getAccessTime();</div><div class="line">		System.out.println(<span class="string">"access:"</span>+formatter.format(<span class="keyword">new</span> Date(accessTime)));</div><div class="line">		</div><div class="line">		<span class="comment">//获取文件修改时间，返回long</span></div><div class="line">		<span class="keyword">long</span> modificationTime = fileStatus.getModificationTime();</div><div class="line">		System.out.println(<span class="string">"modification:"</span>+formatter.format(<span class="keyword">new</span> Date(modificationTime)));</div><div class="line">		</div><div class="line">		<span class="comment">//获取块大小，单位B</span></div><div class="line">		<span class="keyword">long</span> blockSize = fileStatus.getBlockSize();</div><div class="line">		System.out.println(<span class="string">"blockSize:"</span>+blockSize);</div><div class="line">		</div><div class="line">		<span class="comment">//获取文件大小，单位B</span></div><div class="line">		<span class="keyword">long</span> len = fileStatus.getLen();</div><div class="line">		System.out.println(<span class="string">"length:"</span>+len);</div><div class="line">		</div><div class="line">		<span class="comment">//获取文件拥有者</span></div><div class="line">		String ower = fileStatus.getOwner();</div><div class="line">		System.out.println(<span class="string">"owner:"</span>+ower);</div><div class="line">		</div><div class="line">		<span class="comment">//获取文件所在用户组</span></div><div class="line">		String group = fileStatus.getGroup();</div><div class="line">		System.out.println(<span class="string">"group:"</span>+group);</div><div class="line">		</div><div class="line">		<span class="comment">//获取文件拷贝数</span></div><div class="line">		<span class="keyword">short</span> replication = fileStatus.getReplication();</div><div class="line">		System.out.println(<span class="string">"replication:"</span>+replication);</div><div class="line">		</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><p>从 HDFS 下载文件到本地非常简单，直接调用 FileSystem.copyToLocalFile(Path src, Path dst)即可。其中 src 为 HDFS 上的文件， dst 为要下载到本地的文件名，示例如下。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.hdfs;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"><span class="keyword">import</span> java.net.URISyntaxException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GetFile</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> URISyntaxException, IOException </span>&#123;</div><div class="line">		<span class="comment">// TODO Auto-generated method stub</span></div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		URI uri = <span class="keyword">new</span> URI(<span class="string">"hdfs://master:9000"</span>);</div><div class="line">		FileSystem fs = FileSystem.get(uri, conf);</div><div class="line">		</div><div class="line">		<span class="comment">//hdfs上的文件</span></div><div class="line">		Path src = <span class="keyword">new</span> Path(<span class="string">"/file"</span>);</div><div class="line">		<span class="comment">//下载到本地的文件名</span></div><div class="line">		Path dst = <span class="keyword">new</span> Path(<span class="string">"F:/newfile"</span>);</div><div class="line">		<span class="comment">//下载文件</span></div><div class="line">		fs.copyToLocalFile(src, dst);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>结果中会出现一个crc文件，里面保存了对 file 文件的循环校验信息，如下图所示。</p>
<center><img src="http://i.imgur.com/SzawpvH.png" alt=""></center>


<h3 id="删除文件"><a href="#删除文件" class="headerlink" title="删除文件"></a>删除文件</h3><p>从　HDFS 上删除文件非常简单，直接调用 FileSystem.delete(Path path, Boolean b)即可。其中 path 为要删除的文件，示例如下。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.hdfs;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"><span class="keyword">import</span> java.net.URISyntaxException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DeleteFile</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> URISyntaxException, IOException </span>&#123;</div><div class="line">		<span class="comment">// TODO Auto-generated method stub</span></div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		URI uri = <span class="keyword">new</span> URI(<span class="string">"hdfs://master:9000"</span>);</div><div class="line">		FileSystem fs = FileSystem.get(uri, conf);</div><div class="line">		</div><div class="line">		<span class="comment">//HDFS上删除的文件</span></div><div class="line">		Path delPath = <span class="keyword">new</span> Path(<span class="string">"/file"</span>);</div><div class="line">		<span class="keyword">if</span> (fs.exists(delPath)) &#123;</div><div class="line">			fs.delete(delPath);</div><div class="line">			System.out.println(delPath+<span class="string">" has been deleted sucessfully."</span>);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> &#123;</div><div class="line">			System.out.println(delPath + <span class="string">" deleted failed."</span>);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="java-net-URL"><a href="#java-net-URL" class="headerlink" title="java.net.URL"></a>java.net.URL</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.hdfs;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.net.MalformedURLException;</div><div class="line"><span class="keyword">import</span> java.net.URL;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FsUrlStreamHandlerFactory;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"></div><div class="line"><span class="comment">/*该程序是从HDSF中读取文件最简单的方式，</span></div><div class="line"> * 即用java.net.URL对象打开数据流。</div><div class="line"> * */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DescURL</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="comment">//让Java程序识别Hadoop的HDFS url</span></div><div class="line">	<span class="keyword">static</span>&#123;</div><div class="line">		URL.setURLStreamHandlerFactory(</div><div class="line">				<span class="keyword">new</span> FsUrlStreamHandlerFactory());</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span></div><div class="line">			<span class="keyword">throws</span> MalformedURLException, IOException &#123;</div><div class="line">		InputStream in = <span class="keyword">null</span>;</div><div class="line">		<span class="keyword">try</span> &#123;</div><div class="line">			in = <span class="keyword">new</span> URL(args[<span class="number">0</span>]).openStream();</div><div class="line">			IOUtils.copyBytes(in, System.out, <span class="number">4096</span>,<span class="keyword">false</span>);</div><div class="line">		&#125; <span class="keyword">finally</span> &#123;</div><div class="line">			IOUtils.closeStream(in);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cn.itcast.hadoop.hdfs;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.io.IOUtils;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.LocatedFileStatus;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.RemoteIterator;</div><div class="line"><span class="keyword">import</span> org.junit.Before;</div><div class="line"><span class="keyword">import</span> org.junit.Test;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsUtil</span> </span>&#123;</div><div class="line">	</div><div class="line">	FileSystem fs = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">	</div><div class="line">	<span class="meta">@Before</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">		</div><div class="line">		<span class="comment">//读取classpath下的xxx-site.xml 配置文件，并解析其内容，封装到conf对象中</span></div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		</div><div class="line">		<span class="comment">//也可以在代码中对conf中的配置信息进行手动设置，会覆盖掉配置文件中的读取的值</span></div><div class="line">		conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://weekend110:9000/"</span>);</div><div class="line">		</div><div class="line">		<span class="comment">//根据配置信息，去获取一个具体文件系统的客户端操作实例对象</span></div><div class="line">		fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://weekend110:9000/"</span>),conf,<span class="string">"hadoop"</span>);</div><div class="line">		</div><div class="line">		</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	</div><div class="line">	</div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 上传文件，比较底层的写法</div><div class="line">	 * </div><div class="line">	 * <span class="doctag">@throws</span> Exception</div><div class="line">	 */</div><div class="line">	<span class="meta">@Test</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">upload</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://weekend110:9000/"</span>);</div><div class="line">		</div><div class="line">		FileSystem fs = FileSystem.get(conf);</div><div class="line">		</div><div class="line">		Path dst = <span class="keyword">new</span> Path(<span class="string">"hdfs://weekend110:9000/aa/qingshu.txt"</span>);</div><div class="line">		</div><div class="line">		FSDataOutputStream os = fs.create(dst);</div><div class="line">		</div><div class="line">		FileInputStream is = <span class="keyword">new</span> FileInputStream(<span class="string">"c:/qingshu.txt"</span>);</div><div class="line">		</div><div class="line">		IOUtils.copy(is, os);</div><div class="line">		</div><div class="line"></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 上传文件，封装好的写法</div><div class="line">	 * <span class="doctag">@throws</span> Exception</div><div class="line">	 * <span class="doctag">@throws</span> IOException</div><div class="line">	 */</div><div class="line">	<span class="meta">@Test</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">upload2</span><span class="params">()</span> <span class="keyword">throws</span> Exception, IOException</span>&#123;</div><div class="line">		</div><div class="line">		fs.copyFromLocalFile(<span class="keyword">new</span> Path(<span class="string">"c:/qingshu.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"hdfs://weekend110:9000/aaa/bbb/ccc/qingshu2.txt"</span>));</div><div class="line">		</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	</div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 下载文件</div><div class="line">	 * <span class="doctag">@throws</span> Exception </div><div class="line">	 * <span class="doctag">@throws</span> IllegalArgumentException </div><div class="line">	 */</div><div class="line">	<span class="meta">@Test</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">download</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		</div><div class="line">		fs.copyToLocalFile(<span class="keyword">new</span> Path(<span class="string">"hdfs://weekend110:9000/aa/qingshu2.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"c:/qingshu2.txt"</span>));</div><div class="line"></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 查看文件信息</div><div class="line">	 * <span class="doctag">@throws</span> IOException </div><div class="line">	 * <span class="doctag">@throws</span> IllegalArgumentException </div><div class="line">	 * <span class="doctag">@throws</span> FileNotFoundException </div><div class="line">	 * </div><div class="line">	 */</div><div class="line">	<span class="meta">@Test</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFiles</span><span class="params">()</span> <span class="keyword">throws</span> FileNotFoundException, IllegalArgumentException, IOException </span>&#123;</div><div class="line"></div><div class="line">		<span class="comment">// listFiles列出的是文件信息，而且提供递归遍历</span></div><div class="line">		RemoteIterator&lt;LocatedFileStatus&gt; files = fs.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</div><div class="line">		</div><div class="line">		<span class="keyword">while</span>(files.hasNext())&#123;</div><div class="line">			</div><div class="line">			LocatedFileStatus file = files.next();</div><div class="line">			Path filePath = file.getPath();</div><div class="line">			String fileName = filePath.getName();</div><div class="line">			System.out.println(fileName);</div><div class="line">			</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		System.out.println(<span class="string">"---------------------------------"</span>);</div><div class="line">		</div><div class="line">		<span class="comment">//listStatus 可以列出文件和文件夹的信息，但是不提供自带的递归遍历</span></div><div class="line">		FileStatus[] listStatus = fs.listStatus(<span class="keyword">new</span> Path(<span class="string">"/"</span>));</div><div class="line">		<span class="keyword">for</span>(FileStatus status: listStatus)&#123;</div><div class="line">			</div><div class="line">			String name = status.getPath().getName();</div><div class="line">			System.out.println(name + (status.isDirectory()?<span class="string">" is dir"</span>:<span class="string">" is file"</span>));</div><div class="line">			</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 创建文件夹</div><div class="line">	 * <span class="doctag">@throws</span> Exception </div><div class="line">	 * <span class="doctag">@throws</span> IllegalArgumentException </div><div class="line">	 */</div><div class="line">	<span class="meta">@Test</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, Exception </span>&#123;</div><div class="line"></div><div class="line">		fs.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/aaa/bbb/ccc"</span>));</div><div class="line">		</div><div class="line">		</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">/**</span></div><div class="line">	 * 删除文件或文件夹</div><div class="line">	 * <span class="doctag">@throws</span> IOException </div><div class="line">	 * <span class="doctag">@throws</span> IllegalArgumentException </div><div class="line">	 */</div><div class="line">	<span class="meta">@Test</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rm</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</div><div class="line"></div><div class="line">		fs.delete(<span class="keyword">new</span> Path(<span class="string">"/aa"</span>), <span class="keyword">true</span>);</div><div class="line">		</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://weekend110:9000/"</span>);</div><div class="line">		</div><div class="line">		FileSystem fs = FileSystem.get(conf);</div><div class="line">		</div><div class="line">		FSDataInputStream is = fs.open(<span class="keyword">new</span> Path(<span class="string">"/jdk-7u65-linux-i586.tar.gz"</span>));</div><div class="line">		</div><div class="line">		FileOutputStream os = <span class="keyword">new</span> FileOutputStream(<span class="string">"c:/jdk7.tgz"</span>);</div><div class="line">		</div><div class="line">		IOUtils.copy(is, os);</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Kafka集群安装</title>
    <link href="https://freeshow.github.io/BigData/Kafka/Kafka%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/"/>
    <id>https://freeshow.github.io/BigData/Kafka/Kafka集群安装/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T11:20:35.924Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h1 id="一、安装ZooKeeper集群"><a href="#一、安装ZooKeeper集群" class="headerlink" title="一、安装ZooKeeper集群"></a>一、安装ZooKeeper集群</h1><p>可以参考我的博客： <a href="https://freeshow.github.io/BigData/ZooKeeper/ZooKeeper%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/">ZooKeeper集群安装</a></p>
<h1 id="二、-安装Kafka集群"><a href="#二、-安装Kafka集群" class="headerlink" title="二、 安装Kafka集群"></a>二、 安装Kafka集群</h1><h2 id="1-解压"><a href="#1-解压" class="headerlink" title="1. 解压"></a>1. 解压</h2><p>在master节点上：</p>
<p>去Apache Kafka官网下载压缩包，我下载的是 <code>kafka_2.11-0.10.0.0.tgz</code></p>
<p>解压到<code>/opt</code>目录下，并重命名为kafka<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxvf kafka_2.11-0.10.0.0.tgz -C /opt</div><div class="line">cd /opt</div><div class="line">sudo mv kafka_2.11-0.10.0.0 kafka</div></pre></td></tr></table></figure></p>
<h2 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2.修改配置文件"></a>2.修改配置文件</h2><p>修改<code>server.properties</code>配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">broker.id=1		# 其他节点分别为broker.id=2和broker.id=3</div><div class="line">zookeeper.connect=master:2181,slave1:2181,slave2:2181    #设置各zookeeper地址</div></pre></td></tr></table></figure>
<p>将master节点上<code>/opt/kafka</code>发送到其他节点上去，并修改配置文件<code>server.properties</code>中broker.id的值。</p>
<h1 id="三、操作Kafka集群"><a href="#三、操作Kafka集群" class="headerlink" title="三、操作Kafka集群"></a>三、操作Kafka集群</h1><h2 id="1-在各节点上启动ZooKeeper"><a href="#1-在各节点上启动ZooKeeper" class="headerlink" title="1.在各节点上启动ZooKeeper"></a>1.在各节点上启动ZooKeeper</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">zkServer.sh start</div></pre></td></tr></table></figure>
<h2 id="2-在各节点上启动Kafka："><a href="#2-在各节点上启动Kafka：" class="headerlink" title="2.在各节点上启动Kafka："></a>2.在各节点上启动Kafka：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-server-start.sh config/server.properties</div></pre></td></tr></table></figure>
<h2 id="3-在kafka集群中创建一个topic"><a href="#3-在kafka集群中创建一个topic" class="headerlink" title="3.在kafka集群中创建一个topic"></a>3.在kafka集群中创建一个topic</h2><p>以master节点为例，在其他节点上也可以：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-topics.sh --create --zookeeper master:2181 --replication-factor 3 --partitions 1 --topic test		#创建topic: test</div></pre></td></tr></table></figure></p>
<h2 id="4-用一个producer向某一个topic中写入消息"><a href="#4-用一个producer向某一个topic中写入消息" class="headerlink" title="4.用一个producer向某一个topic中写入消息"></a>4.用一个producer向某一个topic中写入消息</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-console-producer.sh --broker-list master:9092 --topic test</div></pre></td></tr></table></figure>
<h2 id="5-用一个comsumer从某一个topic中读取信息"><a href="#5-用一个comsumer从某一个topic中读取信息" class="headerlink" title="5.用一个comsumer从某一个topic中读取信息"></a>5.用一个comsumer从某一个topic中读取信息</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-console-consumer.sh --zookeeper master:2181 --from-beginning --topic test</div></pre></td></tr></table></figure>
<p>此次，如果producer输入消息，则comsumer就是收到消息。</p>
<p>当然，这只是命令行的形式，实际开发中一般用 Java API编写。</p>
<h2 id="6-查看一个topic的分区及副本状态信息"><a href="#6-查看一个topic的分区及副本状态信息" class="headerlink" title="6.查看一个topic的分区及副本状态信息"></a>6.查看一个topic的分区及副本状态信息</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-topics.sh --describe --zookeeper master:2181 --topic test</div></pre></td></tr></table></figure></the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Windows下使用eclipse编译打包运行自己的MapReduce程序 Hadoop2.6.0</title>
    <link href="https://freeshow.github.io/BigData/Hadoop/Windows%E4%B8%8B%E4%BD%BF%E7%94%A8eclipse%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E8%BF%90%E8%A1%8C%E8%87%AA%E5%B7%B1%E7%9A%84MapReduce%E7%A8%8B%E5%BA%8F%20Hadoop2.6.0/"/>
    <id>https://freeshow.github.io/BigData/Hadoop/Windows下使用eclipse编译打包运行自己的MapReduce程序 Hadoop2.6.0/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T08:53:40.221Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">


<h1 id="一、相关文件准备"><a href="#一、相关文件准备" class="headerlink" title="一、相关文件准备"></a>一、相关文件准备</h1><h2 id="1-java-JDK-for-Windows"><a href="#1-java-JDK-for-Windows" class="headerlink" title="1. java JDK for Windows"></a>1. java JDK for Windows</h2><h2 id="2-hadoop-2-6-4-tar-gz-就是安装hadoop时使用的文件"><a href="#2-hadoop-2-6-4-tar-gz-就是安装hadoop时使用的文件" class="headerlink" title="2. hadoop-2.6.4.tar.gz 就是安装hadoop时使用的文件"></a>2. hadoop-2.6.4.tar.gz 就是安装hadoop时使用的文件</h2><h2 id="3-Eclipse-JEE版本"><a href="#3-Eclipse-JEE版本" class="headerlink" title="3. Eclipse JEE版本"></a>3. Eclipse JEE版本</h2><p><img src="http://i.imgur.com/dbjp1oz.png" alt=""></p>
<h1 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h1><h2 id="1-安装java并配置环境"><a href="#1-安装java并配置环境" class="headerlink" title="1.安装java并配置环境"></a>1.安装java并配置环境</h2><p>自己百度</p>
<h2 id="2-解压hadoop-2-6-4-tar-gz源文件"><a href="#2-解压hadoop-2-6-4-tar-gz源文件" class="headerlink" title="2.解压hadoop-2.6.4.tar.gz源文件"></a>2.解压hadoop-2.6.4.tar.gz源文件</h2><p>Hadoop源文件在整个开发过程中都会用到，因为很多依赖包都出自里面，用户可按自己的喜好选择位置，但路径层次最好不要太多，本文选在解压到E盘根目录下，即<code>E:\hadoop-2.6.4</code></p>
<h2 id="3-安装Eclipse"><a href="#3-安装Eclipse" class="headerlink" title="3.安装Eclipse"></a>3.安装Eclipse</h2><p>自己百度</p>
<h1 id="三、使用Eclipse创建一个Java工程"><a href="#三、使用Eclipse创建一个Java工程" class="headerlink" title="三、使用Eclipse创建一个Java工程"></a>三、使用Eclipse创建一个Java工程</h1><p>使用Eclipse创建一个名为<code>wordcound</code>的Java工程</p>
<h1 id="四、导入Hadoop的相关jar包"><a href="#四、导入Hadoop的相关jar包" class="headerlink" title="四、导入Hadoop的相关jar包"></a>四、导入Hadoop的相关jar包</h1><p>在编写MapReduce代码时，需要用到Hadoop源文件中的部分Jar包，就像在编写纯Java代码时需要使用Java自带的依赖包一样，所以这里需要把相应的Hadoop依赖包导入工程。</p>
<p>现在工程 wordcount上右键，在弹出的菜单中选择第一个 New（新建），在选择Folder(文件),名称填上lib; 然后在把下面目录下的jar包复制到lib文件夹下(之前把Hadoop源文件解压到E盘根目录下)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">E:\hadoop-2.6.4\share\hadoop\common</div><div class="line">E:\hadoop-2.6.4\share\hadoop\common\lib</div><div class="line">E:\hadoop-2.6.4\share\hadoop\common\lib\hadoop-hdfs-2.6.4.jar</div><div class="line">E:\hadoop-2.6.4\share\hadoop\mapreduce</div><div class="line">E:\hadoop-2.6.4\share\hadoop\yarn</div></pre></td></tr></table></figure>
<p>导入Jar包后，还需要把这些jar包添加到工程的构建路径，否则工程并不能识别。选中所有的jar包然后单击右键，选择Build Path -&gt; Add to Build Path.</p>
<p>上面就是Eclipse导入jar包的其中一种方法，其他方法也可以，只要让Eclipse程序能够引用上面的Jar包即可。</p>
<h1 id="五、-MapReduce-代码实现"><a href="#五、-MapReduce-代码实现" class="headerlink" title="五、 MapReduce 代码实现"></a>五、 MapReduce 代码实现</h1><p>本代码演示 wordcount程序。</p>
<p>MapReduce代码实现并不难，这里要编写3个类，分别是WordMapper类、WordReducer类和WordMain驱动类，前面两个类分别实现相应的 Map 和 Reduce 方法，后面一个则是对任务的创建进行部署。</p>
<p>分别创建这3个类，并放入wordcount package下，目录结构如下：</p>
<p><img src="http://i.imgur.com/w9gmeGt.png" alt=""></p>
<h2 id="WordMapper-java"><a href="#WordMapper-java" class="headerlink" title="WordMapper.java"></a>WordMapper.java</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> wordcount;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.StringTokenizer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line"><span class="comment">//创建一个 WordMapper 类继承与 Mapper 抽象类</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">	<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</div><div class="line">	<span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</div><div class="line">	</div><div class="line">	<span class="comment">//Mapper 抽象类的核心方法，三个参数</span></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key,	//首字符偏移量	 </span></span></div><div class="line">					  Text value, 	//文件的一行内容</div><div class="line">					  Context context)	<span class="comment">//Mapper端的上下文</span></div><div class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		<span class="comment">//默认使用空格分隔</span></div><div class="line">		StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</div><div class="line">		<span class="keyword">while</span>(itr.hasMoreTokens())&#123;</div><div class="line">			word.set(itr.nextToken());</div><div class="line">			context.write(word, one);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>map函数实现了对传入值的解析，将value解析成<code>&lt;key, value&gt;</code>的形式，然后使用<code>context.write(word, one)</code>进行输出。</p>
<h2 id="WordReducer-java"><a href="#WordReducer-java" class="headerlink" title="WordReducer.java"></a>WordReducer.java</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> wordcount;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="comment">//创建一个 WordReducer 类继承与 Reducer 抽象类</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</div><div class="line">	<span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();	<span class="comment">//记录词频</span></div><div class="line">	</div><div class="line">	<span class="comment">// Reducer 抽象类的核心方法，3个参数</span></div><div class="line">	<span class="meta">@Override</span></div><div class="line">	<span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key,	//Map 端输出的 key 值</span></span></div><div class="line">						Iterable&lt;IntWritable&gt; values,	//Map 端输出的 Value 集合</div><div class="line">						Context context)	<span class="comment">//Reducer端上下文</span></div><div class="line">						<span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">		<span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">		</div><div class="line">		<span class="keyword">for</span> (IntWritable var : values) &#123;	<span class="comment">//遍历 values 集合，并把值相加</span></div><div class="line">			sum += var.get();</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		result.set(sum);	<span class="comment">//得到最终词频数</span></div><div class="line">		context.write(key, result);		<span class="comment">//写入结果</span></div><div class="line">		</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>reduce方法中，将获取的values进行遍历累加，得到相应的key出现的次数，最后将结果写入HDFS。</p>
<h2 id="WordMain-java"><a href="#WordMain-java" class="headerlink" title="WordMain.java"></a>WordMain.java</h2><p>WordMain驱动类主要是在Job中设定相应的Mapper类和Reducer类(用户编写的类)，这样任务运行时才知道使用相应的类进行处理；WordMain驱动类还可以对MapReducer程序进行相应配置，让任务在Hadoop集群运行时按所定义的配置进行。其代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> wordcount;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordMain</span> </span></div><div class="line">&#123;</div><div class="line">	</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span></div><div class="line">	&#123;</div><div class="line">		</div><div class="line">		<span class="comment">// Configuration 类: 读取hadoop的配置文件，如 site-core.xml...;</span></div><div class="line">		<span class="comment">//也可以用set方法重新设置(会覆盖): conf.set("fs.defaultFS","hdfs://master:9000")</span></div><div class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">		</div><div class="line">		<span class="comment">//将命令行中的参数自动设置到变量conf中</span></div><div class="line">		String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf,args).getRemainingArgs();</div><div class="line">		</div><div class="line">		<span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) </div><div class="line">		&#123;</div><div class="line">			System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; &lt;out&gt;"</span>);</div><div class="line">			System.exit(<span class="number">2</span>);</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		Job job = <span class="keyword">new</span> Job(conf,<span class="string">"word count"</span>);	<span class="comment">//新建一个job,传入配置信息</span></div><div class="line">		job.setJarByClass(WordMain.class);	<span class="comment">//设置主类</span></div><div class="line">		job.setMapperClass(WordMapper.class);	<span class="comment">//设置Mapper类</span></div><div class="line">		job.setReducerClass(WordReducer.class);	<span class="comment">//设置Reducer类</span></div><div class="line">		job.setOutputKeyClass(Text.class);	<span class="comment">//设置输出类型</span></div><div class="line">		job.setOutputValueClass(IntWritable.class);	<span class="comment">//设置输出类型</span></div><div class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));	<span class="comment">//设置输入文件</span></div><div class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));	<span class="comment">//设置输出文件</span></div><div class="line">		System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);	<span class="comment">//等待完成退出</span></div><div class="line">		</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>该类中的main方法就是MapReduce程序的入口，在main方法中，首先创建一个Configuration类对象conf用于保存所有的配置信息，该对象在创建时会读取所需要配置文件如 site-core.xml、hdfs-site.xml等，根据配置文件中的变量信息进行初始化，当然配置文件中的配置有时候并不是人们想要的，这时候可以调用Configuration类中的set方法进行覆盖，如想要修改Reducer的数量，可以使用如下方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">conf.set(<span class="string">"mapreduce.job.reduces"</span>,<span class="string">"2"</span>);</div></pre></td></tr></table></figure>
<p>也不是所有的变量都可以修改，有时候集群管理员并不希望用户在应用程序中修改某变量的值，这时候会在相应变量后面添加final属性：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.io.sort.factor<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">final</span>&gt;</span>true<span class="tag">&lt;/<span class="name">final</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure>
<p>这时候，Configuration类中在set上面的属性将不再起左右。</p>
<p>最后，main方法中创建一个Job类对象job,并传入配置信息conf和作业名称。之后对job对象进行相关设置，如Mapper类、Reducer类等。job对象就是最终的作业对象，它里面包含一个作业所需的所有信息。</p>
<p>至此，一个MapReduce程序便开发完成了。</p>
<h1 id="六、打包工程为jar包"><a href="#六、打包工程为jar包" class="headerlink" title="六、打包工程为jar包"></a>六、打包工程为jar包</h1><p>WordCount代码完成后，并不能直接在hadoop中运行，还需要将其打包成jvm所能执行的二进制文件，即打包成.jar文件，才能被hadoop所有。</p>
<p>在WordCount项目上右击，选择Export(导出),在弹出的对话框中选择 JAR file，如下图所示，然后单击Next。之后会进入JAR依赖包过滤对话框，这里只选择src即可，把lib文件夹前的勾选去掉，因为lib中的依赖包本来就是复制的hadoop的源文件，在集群中已经包含了。之后选择一个保存位置，单击Finish即可。</p>
<p><img src="http://i.imgur.com/UGQVGbE.png" alt="选择Jar file"></p>
<p><img src="http://i.imgur.com/sMsTRJx.png" alt="jar依赖包过滤"></p>
<p>打包成wordcount.jar</p>
<p>WordMain驱动类为wordcount.WordMain。</p>
<h1 id="七、部署并运行"><a href="#七、部署并运行" class="headerlink" title="七、部署并运行"></a>七、部署并运行</h1><p>部署其实就把前面打包生成的wordcount.jar包放入集群中运行。hadoop一般会有多个节点，一个namenode节点和多个datanode节点，这里只需要把jar放入namenode中，并使用相应的hadoop命令即可，hadoop集群会把任务传送给需要运行任务的节点。wordcount.jar运行时需要有输入文本。</p>
<h2 id="1-创建测试文本并上传相关文件到namenode中"><a href="#1-创建测试文本并上传相关文件到namenode中" class="headerlink" title="1.创建测试文本并上传相关文件到namenode中"></a>1.创建测试文本并上传相关文件到namenode中</h2><p>为了方便，在桌面上创建测试文本file1.txt、file2.txt。内容分别为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">File: file1.txt					File:file2.txt</div><div class="line">hadoop is very good				hadoop is very good</div><div class="line">mapreduce is very good			 mapreduce is very good</div></pre></td></tr></table></figure>
<p>然后使用WinSCP工具把上述txt文件和wordcount.jar文件一起上传到namenode节点的hadoop用户目录下，hadoop用户指的是安装运行hadoop集群的用户，本文的用户名就为hadoop.</p>
<p>注意：<br>上传结束后，需要查看上传文件的权限是否为hadoop:hadoop(hadoop用户和hadoop组)，如果不是则需要将上传文件的权限改为hadoop:hadoop,命令为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo chown -R hadoop:hadoop file1.txt</div><div class="line">sudo chown -R hadoop:hadoop file2.txt</div><div class="line">sudo chown -R hadoop:hadoop wordcount.jar</div></pre></td></tr></table></figure></p>
<p>如下图所示：</p>
<p><img src="http://i.imgur.com/qlFHGQP.png" alt=""></p>
<h2 id="2-上传测试文件到HDFS"><a href="#2-上传测试文件到HDFS" class="headerlink" title="2.上传测试文件到HDFS"></a>2.上传测试文件到HDFS</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -mkdir input	//创建输入文件夹input</div><div class="line">hdfs dfa -put file* input	//将file1.txt file2.txt放入input文件夹中</div></pre></td></tr></table></figure>
<h2 id="3-在hadoop集群中运行WordCount"><a href="#3-在hadoop集群中运行WordCount" class="headerlink" title="3.在hadoop集群中运行WordCount"></a>3.在hadoop集群中运行WordCount</h2><p>测试文件已经准备完毕，现在要做的就是把任务提交到hadoop集群中。<br>在hadoop中运行jar任务需要使用的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop jar [jar文件位置] [jar 主类] [HDFS输入位置] [HDFS输出位置]</div></pre></td></tr></table></figure></p>
<ul>
<li>hadoop: hadoop脚本命令，如果要直接使用，必须添加相应bin路径到环境变量PATH中。</li>
<li>jar: 表示要运行的是一个基于Java的任务。</li>
<li>jar文件位置： 提供所要运行任务的jar文件位置，如果在当前操作目录下，可直接使用文件名。</li>
<li>jar主类： 提供入口函数所在的类，格式为[包名.]类名</li>
<li>HDFS输入位置： 指定输入文件在HDFS中的位置。</li>
<li>HDFS输出位置： 执行输出文件在HDFS中的存储位置，该位置必须不存在，否则任务不会运行，该机制就是为了防止文件被覆盖出现意外丢失。</li>
</ul>
<p>本例的操作命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoor jar wordcount.jar wordcount.WordMain input output</div></pre></td></tr></table></figure></p>
<p>提交任务后，hadoop集群便会开始执行任务，在任务的执行过程中，会出现一系列任务提示或信息进度，如下所示：</p>
<p><img src="http://i.imgur.com/IaQSzgL.png" alt=""></p>
<h2 id="4-查看任务结果"><a href="#4-查看任务结果" class="headerlink" title="4.查看任务结果"></a>4.查看任务结果</h2><p>任务结束保存在设定的输出目录中，如下图所示：</p>
<p><img src="http://i.imgur.com/3MBdhW4.png" alt=""></p>
<ul>
<li>_SUCCESS： 该文件中无任何内容，生成它主要是为了使hadoop集群检测并停止任务。</li>
<li>part-r-00000： 由Reducer生成的结果文件，一般来说一个Reducer生成一个，本例中只有一个Reducer运行，所以结果文件只有一个。</li>
</ul>
<p>可以使用hdfs dfs中的-cat命令查看结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -cat output/*</div></pre></td></tr></table></figure>
<p>结果如下图所示：</p>
<p><img src="http://i.imgur.com/hooLx5f.png" alt=""></p>
<p>至此，一个MapReducer程序的开发过程就结束了。</p>
<h2 id="本文转自：《Hadoop大数据处理技术基础与实践》–安俊秀-编著"><a href="#本文转自：《Hadoop大数据处理技术基础与实践》–安俊秀-编著" class="headerlink" title="本文转自：《Hadoop大数据处理技术基础与实践》–安俊秀 编著"></a>本文转自：《Hadoop大数据处理技术基础与实践》–安俊秀 编著</h2></the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>ZooKeeper集群安装</title>
    <link href="https://freeshow.github.io/BigData/ZooKeeper/ZooKeeper%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/"/>
    <id>https://freeshow.github.io/BigData/ZooKeeper/ZooKeeper集群安装/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T11:29:44.674Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<p>环境基于上篇博客的搭建环境： <a href="https://freeshow.github.io/BigData/Hadoop/Hadoop分布式集群安装/">Hadoop分布式集群安装</a></p>
<p>有三台虚拟机：master,slave1,slave2</p>
<h1 id="一、安装步骤"><a href="#一、安装步骤" class="headerlink" title="一、安装步骤"></a>一、安装步骤</h1><p>1.下载ZooKeeper: 去 Apache ZooKeeper官网下载，我下载的为 <code>zookeeper-3.4.8.tar.gz</code>.</p>
<p>2.解压：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxf zookeeper-3.4.8.tar.gz -C /opt 	#解压到/opt目录下</div><div class="line">cd /opt</div><div class="line">sudo mv zookeeper-3.4.8 zookeeper		#重命名为zookeeper</div></pre></td></tr></table></figure>
<p>3.创建ZooKeeper的data目录</p>
<p>为了便于管理我创建了ZooKeeper安装目录下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir /opt/zookeeper/data</div></pre></td></tr></table></figure></p>
<p>4.创建myid文件</p>
<p>在<code>/opt/zookeeper/data</code>文件夹下创建文件<code>myid</code>,并输入内容 1。其余节点分别为2和3。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /opt/zookeeper/data</div><div class="line">vi myid 	#输入1,其他节点分别输入2和3</div></pre></td></tr></table></figure>
<p>5.配置文件</p>
<p>在conf目录下创建一个配置文件zoo.cfg:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cp zoo_sample.cfg zoo.cfg</div><div class="line">sudo vi zoo.cfg</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"># The number of milliseconds of each tick</div><div class="line">tickTime=2000</div><div class="line"># The number of ticks that the initial </div><div class="line"># synchronization phase can take</div><div class="line">initLimit=10</div><div class="line"># The number of ticks that can pass between </div><div class="line"># sending a request and getting an acknowledgement</div><div class="line">syncLimit=5</div><div class="line"># the directory where the snapshot is stored.</div><div class="line"># do not use /tmp for storage, /tmp here is just </div><div class="line"># example sakes.</div><div class="line">dataDir=/opt/zookeeper/data/</div><div class="line"># the port at which the clients will connect</div><div class="line">clientPort=2181</div><div class="line"># the maximum number of client connections.</div><div class="line"># increase this if you need to handle more clients</div><div class="line">#maxClientCnxns=60</div><div class="line">#</div><div class="line"># Be sure to read the maintenance section of the </div><div class="line"># administrator guide before turning on autopurge.</div><div class="line">#</div><div class="line"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</div><div class="line">#</div><div class="line"># The number of snapshots to retain in dataDir</div><div class="line">#autopurge.snapRetainCount=3</div><div class="line"># Purge task interval in hours</div><div class="line"># Set to &quot;0&quot; to disable auto purge feature</div><div class="line">#autopurge.purgeInterval=1</div><div class="line"></div><div class="line">server.1=master:2888:3888</div><div class="line">server.2=slave1:2888:3888</div><div class="line">server.3=slave2:2888:3888</div></pre></td></tr></table></figure>
<h1 id="二、最低配置要求中必须配置的参数"><a href="#二、最低配置要求中必须配置的参数" class="headerlink" title="二、最低配置要求中必须配置的参数"></a>二、最低配置要求中必须配置的参数</h1><ol>
<li>clent: 监听客户端连接的端口</li>
<li>tickTime: 基本时间单元，这个时间作为ZooKeeper服务器之间或客户端与服务器之间维持心跳的时间间隔。</li>
<li>dataDir: 存储内存中数据库快照的位置。</li>
</ol>
<h1 id="三、集群配置"><a href="#三、集群配置" class="headerlink" title="三、集群配置"></a>三、集群配置</h1><ol>
<li>initLimit: 此配置表示，允许follower(相对于Leader而言的“客户端”)连接并同步到Leader的初始化连接时间。</li>
<li>syncLimit: 此配置项表示Leader和Follower之间发送消息时，请求和应答得时间长度。</li>
<li>server.A=B: C: D。 其中A是一个数字，表示这个是服务器的编号(myid文件中的数字)；B是这个服务器的IP地址；C是Leader选举的端口；D是ZooKeeper服务器之间的通信端口。</li>
<li>myid和zoo.cfg。除了zoo.cfg配置文件外，集群模式下还要配置一个文件myid,这个文件在dataDir目录下，这个文件里就有一个数据就是A的值，ZooKeeper启动时会读取这个文件，拿到里面的数据和zoo.cfg里面的配置信息做比较，从而判断是哪个server.</li>
</ol>
<h1 id="四、启动ZooKeeper"><a href="#四、启动ZooKeeper" class="headerlink" title="四、启动ZooKeeper"></a>四、启动ZooKeeper</h1><p>将 <code>/opt/zookeeper/bin</code>加入到Path文件路径中。</p>
<p>配置好之后，可以通过下面命令对ZooKeeper进行操作。</p>
<ol>
<li>在3个节点上分别执行命令 zkServer.sh start 启动 ZooKeeper。</li>
<li>在3个节点上分别执行命令 zkServer.sh status 检查节点状态。</li>
<li>在3个节点上分别执行命令 zkServer.sh stop 关闭 ZooKeeper。</li>
</ol>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://freeshow.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Spark安装和集群部署</title>
    <link href="https://freeshow.github.io/BigData/Spark/Spark%E5%AE%89%E8%A3%85%E5%92%8C%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/"/>
    <id>https://freeshow.github.io/BigData/Spark/Spark安装和集群部署/</id>
    <published>2017-03-27T04:22:51.000Z</published>
    <updated>2017-03-28T11:29:12.941Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h1 id="一、搭建Hadoop分布式集群"><a href="#一、搭建Hadoop分布式集群" class="headerlink" title="一、搭建Hadoop分布式集群"></a>一、搭建Hadoop分布式集群</h1><p>参考 <a href="https://freeshow.github.io/BigData/Hadoop/Hadoop分布式集群安装/">Hadoop分布式集群安装</a> 进行搭建</p>
<h1 id="二、Spark安装和集群部署"><a href="#二、Spark安装和集群部署" class="headerlink" title="二、Spark安装和集群部署"></a>二、Spark安装和集群部署</h1><h2 id="1-安装Scala"><a href="#1-安装Scala" class="headerlink" title="1.安装Scala"></a>1.安装Scala</h2><p>Spark对配套的Scala版本有规定，所以要根据自己的实际情况来选择Scala的版本。</p>
<p>如下图所示：</p>
<center><img src="http://i.imgur.com/YYVi9s9.png" alt=""></center>

<p>由于Hadoop我们安装的是2.6.4，故我们选择上图中与Hadoop配套的Spark，因而选择Scala的版本为2.11。</p>
<p>我下载的Scala为<code>scala-2.11.8.tgz</code></p>
<p>(1)解压并放到相应的目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar -zxvf scala-2.11.8.tgz -C /opt/		#解压到/opt/目录下</div><div class="line">cd /opt/</div><div class="line">mv scala-2.11.8.tgz scala	#重名为scala</div></pre></td></tr></table></figure>
<p>(2)配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vi /etc/profile</div></pre></td></tr></table></figure>
<p>在文件最后添加如下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># set scala env</div><div class="line">export SCALA_HOME=/opt/scala</div><div class="line">export PATH=$PATH:$SCALA_HOME/bin</div></pre></td></tr></table></figure>
<p>(3)在终端输入<code>scala</code>，进入Scala的命令交互式界面，则安装成功。</p>
<p>注意：</p>
<blockquote>
<p>由于Spark需要运行在三台机器上，另外两台同样需要安装Scala。</p>
</blockquote>
<h2 id="2-安装Spark和集群部署"><a href="#2-安装Spark和集群部署" class="headerlink" title="2.安装Spark和集群部署"></a>2.安装Spark和集群部署</h2><p>Spark需要运行在三台机器上，这里先安装 Spark 到 master 这台机器上，另外两台的安装方法一致，也可以使用SSH的<code>scp</code>命令把master机器上安装好的Spark目录复制到另外两台机器相同目录下。</p>
<p>(1)下载并解压</p>
<p>从Spark官网下载Spark安装包，我下载的是<code>spark-2.0.0-bin-hadoop2.6.tgz</code>。下载完后解压，并存放到自己指定的存储目录下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxvf spark-2.0.0-bin-hadoop2.6.tgz -C /opt</div><div class="line">cd /opt</div><div class="line">mv spark-2.0.0-bin-hadoop2.6 spark</div></pre></td></tr></table></figure>
<p>(2)配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vi /etc/profile</div></pre></td></tr></table></figure>
<p>在文件末尾添加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># set spark env</div><div class="line">export SPARK_HOME=/opt/spark</div><div class="line">export PATH=$PATH:$SPARK_HOME/bin</div></pre></td></tr></table></figure></p>
<p>并使配置文件生效：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">source /etc/profile</div></pre></td></tr></table></figure></p>
<p>(3)配置Spark,需要配置<code>spark-env.sh</code>和<code>slaves</code>文件。</p>
<p>配置<code>spark-env.sh</code>文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd /opt/spark/conf</div><div class="line">cp spark-defaults.conf.template spark-env.sh</div><div class="line">vi spark-env.sh</div></pre></td></tr></table></figure></p>
<p>配置内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=/opt/java</div><div class="line">export SCALA_HOME=/opt/scala</div><div class="line">export HADOOP_HOME=/opt/hadoop</div><div class="line">export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop</div><div class="line">export SPARK_MASTER_IP=master</div></pre></td></tr></table></figure>
<blockquote>
<p>SPARK_MASTER_IP: Spark集群的Master节点的IP地址。</p>
</blockquote>
<p>配置slaves文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cp slaves.template slaves</div><div class="line">vi slaves</div></pre></td></tr></table></figure>
<p>把Worker节点的主机名都添加进去，修改后的内容为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">slave1</div><div class="line">slave2</div></pre></td></tr></table></figure></p>
<p>(4) 按照上述配置，将Spark安装到另外两台机器上(slave1、slave2)</p>
<p>(5) 启动并测试集群的情况</p>
<p> 1)当前我们只使用Hadoop的HDFS文件系统，所以可以只启动Hadoop的HDFS文件系统。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">start-dfs.sh</div></pre></td></tr></table></figure></p>
<p> 2)用Spark的sbin目录下的<code>start-all.sh</code>命令启动Spark集群，这里需要注意的是，在命令终端必须写成<code>./start-all.sh</code>，因为在Hadoop的sbin目录下也有一个<code>start-all.sh</code>可执行文件。</p>
<p> 3)此时使用JPS在master节点、slave1节点和slave2节点分别可以查看到新开启的Master和Worker进程。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">hadoop@master:~$ jps</div><div class="line">3570 NameNode</div><div class="line">3908 Master</div><div class="line">3978 Jps</div><div class="line">3790 SecondaryNameNode</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hadoop@slave1:~$ jps</div><div class="line">1826 Worker</div><div class="line">1939 Jps</div><div class="line">1689 DataNode</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hadoop@slave2:~$ jps</div><div class="line">1826 Worker</div><div class="line">1939 Jps</div><div class="line">1689 DataNode</div></pre></td></tr></table></figure>
<p> 4)可以进入Spark的WebUI页面，访问<code>master:8080</code>,如下如所示(8080为Spark的WebUI监听端口，7077为Spark集群的Master内部监听端口)。</p>
<center><img src="http://i.imgur.com/NzIiwOC.png" alt=""></center>

<p> 5)进入Spark的bin目录，使用<code>spark-shell</code>命令可以进入spark - shell控制台：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">hadoop@master:~$ spark-shell </div><div class="line">Setting default log level to &quot;WARN&quot;.</div><div class="line">To adjust logging level use sc.setLogLevel(newLevel).</div><div class="line">16/08/15 13:18:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</div><div class="line">16/08/15 13:18:40 WARN spark.SparkContext: Use an existing SparkContext, some configuration may not take effect.</div><div class="line">Spark context Web UI available at http://192.168.1.104:4040</div><div class="line">Spark context available as &apos;sc&apos; (master = local[*], app id = local-1471238319919).</div><div class="line">Spark session available as &apos;spark&apos;.</div><div class="line">Welcome to</div><div class="line">      ____              __</div><div class="line">     / __/__  ___ _____/ /__</div><div class="line">    _\ \/ _ \/ _ `/ __/  &apos;_/</div><div class="line">   /___/ .__/\_,_/_/ /_/\_\   version 2.0.0</div><div class="line">      /_/</div><div class="line">         </div><div class="line">Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_91)</div><div class="line">Type in expressions to have them evaluated.</div><div class="line">Type :help for more information.</div><div class="line"></div><div class="line">scala&gt;</div></pre></td></tr></table></figure>
<p>我们也可以在WebUI页面输入<code>http://master:4040</code>从Web的角度了解Spark-Shell。</p>
<p>这时，Spark集群部署成功。</p>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://freeshow.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Spark" scheme="https://freeshow.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>GitHub Pages + Hexo搭建个人博客</title>
    <link href="https://freeshow.github.io/Comprehensive/BuildBlog/GitHub%20Pages%20+%20Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>https://freeshow.github.io/Comprehensive/BuildBlog/GitHub Pages + Hexo搭建个人博客/</id>
    <published>2017-03-27T04:01:01.000Z</published>
    <updated>2017-03-28T09:05:13.701Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<p>参考自：<a href="http://crazymilk.github.io/2015/12/28/GitHub-Pages-Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/#more" target="_blank" rel="external">GitHub Pages + Hexo搭建博客</a></p>
<h1 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h1><p>这是一篇使用GitHub Pages和Hexo搭建免费独立博客的总结。</p>
<p>如果你厌恶了第三方博客系统的广告的繁琐的事情或想搭建自己的个性博客，我想这是一个不错的选择。</p>
<p>如果你是一个小小白，可以先花时间了解下以下内容：</p>
<ul>
<li><a href="http://git-scm.com/book/zh/v2" target="_blank" rel="external">Git</a></li>
<li><a href="https://github.com/" target="_blank" rel="external">GitHub</a></li>
<li><a href="https://pages.github.com/" target="_blank" rel="external">GitHub Pages</a></li>
<li><a href="https://hexo.io/zh-cn/" target="_blank" rel="external">Hexo</a></li>
<li><a href="http://www.appinn.com/markdown/#autoescape" target="_blank" rel="external">Markdown</a></li>
</ul>
<h1 id="二、必要配置"><a href="#二、必要配置" class="headerlink" title="二、必要配置"></a>二、必要配置</h1><h2 id="2-1-GitHub-Pages-仓库"><a href="#2-1-GitHub-Pages-仓库" class="headerlink" title="2.1 GitHub Pages 仓库"></a>2.1 GitHub Pages 仓库</h2><h3 id="2-1-1-创建对应仓库"><a href="#2-1-1-创建对应仓库" class="headerlink" title="2.1.1 创建对应仓库"></a>2.1.1 创建对应仓库</h3><p>在自己的GitHub账号下创建一个新的仓库，命名为username.github.io（username是你的账号名)。<br>在这里，要知道，GitHub Pages有两种类型：User/Organization Pages 和 Project Pages，而我所使用的是User Pages。</p>
<p>简单来说，User Pages 与 Project Pages的区别是：</p>
<ol>
<li>User Pages 是用来展示用户的，而 Project Pages 是用来展示项目的。</li>
<li>用于存放 User Pages 的仓库必须使用username.github.io的命名规则，而 Project Pages 则没有特殊的要求。</li>
<li>User Pages 将使用仓库的 master 分支，而 Project Pages 将使用 gh-pages 分支。</li>
<li>User Pages 通过 http(s)://username.github.io 进行访问，而 Projects Pages通过 http(s)://username.github.io/projectname 进行访问。</li>
</ol>
<h3 id="2-1-2-相关资料"><a href="#2-1-2-相关资料" class="headerlink" title="2.1.2 相关资料"></a>2.1.2 相关资料</h3><ul>
<li><a href="https://help.github.com/articles/user-organization-and-project-pages/" target="_blank" rel="external">GitHub Pages Basics / User, Organization, and Project Pages</a></li>
</ul>
<h2 id="2-2-Git"><a href="#2-2-Git" class="headerlink" title="2.2 Git"></a>2.2 Git</h2><h3 id="2-2-1-安装Git"><a href="#2-2-1-安装Git" class="headerlink" title="2.2.1 安装Git"></a>2.2.1 安装Git</h3><p>在windows下安装git比较常用的有两种方式：</p>
<ol>
<li><a href="http://git-scm.com/download/win" target="_blank" rel="external">Git 官方版本的安装</a></li>
<li><a href="https://desktop.github.com/" target="_blank" rel="external">GitHub for Windows</a></li>
</ol>
<h3 id="2-2-2-配置Git"><a href="#2-2-2-配置Git" class="headerlink" title="2.2.2 配置Git"></a>2.2.2 配置Git</h3><p>当安装完Git应该做的第一件事情就是设置用户名称和邮件地址。这样做很重要，因为每一个Git的提交都会使用这些信息，并且它会写入你的每一次提交中，不可更改：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ git config --global user.name &quot;username&quot;</div><div class="line">$ git config --global user.email &quot;username@example.com&quot;</div></pre></td></tr></table></figure></p>
<p>对于user.email，因为在GitHub的commits信息上是可见的，所以如果你不想让人知道你的email，可以Keeping your email address private:</p>
<ol>
<li>在GitHub右上方点击你的头像，选择”Settings”；</li>
<li>在右边的”Personal settings”侧边栏选择”Emails”；</li>
<li>选择”Keep my email address private”。</li>
</ol>
<p>这样，你就可以使用如下格式的email进行配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ git config --global user.email &quot;username@users.noreply.github.com&quot;</div></pre></td></tr></table></figure>
<h3 id="2-2-3-相关资料"><a href="#2-2-3-相关资料" class="headerlink" title="2.2.3 相关资料"></a>2.2.3 相关资料</h3><ul>
<li><a href="http://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%AE%89%E8%A3%85-Git" target="_blank" rel="external">安装 Git</a></li>
<li><a href="http://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%88%9D%E6%AC%A1%E8%BF%90%E8%A1%8C-Git-%E5%89%8D%E7%9A%84%E9%85%8D%E7%BD%AE" target="_blank" rel="external">配置 Git</a></li>
<li><a href="https://help.github.com/articles/setting-your-email-in-git/" target="_blank" rel="external">Setting your email in Git</a></li>
<li><a href="https://help.github.com/articles/keeping-your-email-address-private/" target="_blank" rel="external">Keeping your email address private</a></li>
</ul>
<h2 id="2-3-Git与GitHub"><a href="#2-3-Git与GitHub" class="headerlink" title="2.3 Git与GitHub"></a>2.3 Git与GitHub</h2><h3 id="2-3-1-git与github的区别"><a href="#2-3-1-git与github的区别" class="headerlink" title="2.3.1 git与github的区别"></a>2.3.1 git与github的区别</h3><p>这里，我们要区分清楚git与github。<br>git是一个版本控制的工具，而github有点类似于远程仓库，用于存放用git管理的各种项目。</p>
<h3 id="2-3-2-与github建立联系"><a href="#2-3-2-与github建立联系" class="headerlink" title="2.3.2 与github建立联系"></a>2.3.2 与github建立联系</h3><p>为了能够在本地使用git管理github上的项目，需要进行一些配置，这里介绍SSH的方法。</p>
<p>(1) 检查电脑是否已经有SSH keys。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ ls -al ~/.ssh</div><div class="line"># Lists the files in your .ssh directory, if they exist</div></pre></td></tr></table></figure></p>
<p>默认情况下，public keys的文件名是以下的格式之一：id_dsa.pub、id_ecdsa.pub、id_ed25519.pub、id_rsa.pub。因此，如果列出的文件有public和private钥匙对（例如id_ras.pub和id_rsa），证明已存在SSH keys。</p>
<p>(2) 如果没有SSH key，则生成新的SSH key。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</div><div class="line"># Creates a new ssh key, using the provided email as a label</div></pre></td></tr></table></figure>
<p>之后一路回车即可。</p>
<p>(3) 在GitHub添加SSH key。</p>
<p>首先，拷贝key到粘贴板：即将<code>~/.ssh/id_rsa.pub</code>中的内容拷贝到粘贴板。<br>然后，在GitHub右上方点击头像，选择”Settings”，在右边的”Personal settings”侧边栏选择”SSH Keys”。接着粘贴key，点击”Add key”按钮。</p>
<p>(4)相关资料</p>
<ul>
<li><a href="https://help.github.com/articles/generating-ssh-keys/" target="_blank" rel="external">Generating SSH keys</a></li>
</ul>
<h2 id="2-4-Hexo"><a href="#2-4-Hexo" class="headerlink" title="2.4 Hexo"></a>2.4 Hexo</h2><h3 id="2-4-1-安装Hexo"><a href="#2-4-1-安装Hexo" class="headerlink" title="2.4.1 安装Hexo"></a>2.4.1 安装Hexo</h3><p>安装Hexo相当简单。在安装之前，必须检查电脑中是否已经安装下列应用程序：</p>
<ul>
<li><a href="http://nodejs.org/" target="_blank" rel="external">Node.js</a></li>
<li><a href="http://git-scm.com/" target="_blank" rel="external">Git</a></li>
</ul>
<p>如果您的电脑中已经安装上述必备程序，那么恭喜您！接下来只需要使用 npm 即可完成 Hexo 的安装。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ npm install -g hexo-cli</div></pre></td></tr></table></figure></p>
<h3 id="2-4-2-使用Hexo建站"><a href="#2-4-2-使用Hexo建站" class="headerlink" title="2.4.2 使用Hexo建站"></a>2.4.2 使用Hexo建站</h3><p>安装完后，在你喜欢的文件夹内（例如F：\Hexo），点击鼠标右键选择Git bash，输入以下指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo init</div></pre></td></tr></table></figure></p>
<p>该命令会在目标文件夹内建立网站所需要的所有文件。完成后，文件夹目录如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">├── _config.yml</div><div class="line">├── package.json	#所需依赖包文件</div><div class="line">├── scaffolds</div><div class="line">├── source</div><div class="line">|   └── _posts</div><div class="line">└── themes</div><div class="line">|   └── landscape</div></pre></td></tr></table></figure></p>
<p>接下来是安装依赖包：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ npm install</div></pre></td></tr></table></figure></p>
<p>会安装<code>package.json</code>中的默认依赖包。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"># package.json</div><div class="line"></div><div class="line">&#123;</div><div class="line">  &quot;name&quot;: &quot;hexo-site&quot;,</div><div class="line">  &quot;version&quot;: &quot;0.0.0&quot;,</div><div class="line">  &quot;private&quot;: true,</div><div class="line">  &quot;hexo&quot;: &#123;</div><div class="line">    &quot;version&quot;: &quot;3.2.2&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;dependencies&quot;: &#123;</div><div class="line">    &quot;hexo&quot;: &quot;^3.2.0&quot;,</div><div class="line">    &quot;hexo-generator-archive&quot;: &quot;^0.1.4&quot;,</div><div class="line">    &quot;hexo-generator-category&quot;: &quot;^0.1.3&quot;,</div><div class="line">    &quot;hexo-generator-index&quot;: &quot;^0.2.0&quot;,</div><div class="line">    &quot;hexo-generator-tag&quot;: &quot;^0.2.0&quot;,</div><div class="line">    &quot;hexo-renderer-ejs&quot;: &quot;^0.2.0&quot;,</div><div class="line">    &quot;hexo-renderer-marked&quot;: &quot;^0.2.10&quot;,</div><div class="line">    &quot;hexo-renderer-stylus&quot;: &quot;^0.3.1&quot;,</div><div class="line">    &quot;hexo-server&quot;: &quot;^0.2.0&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这样，我们就已经搭建起本地的Hexo博客了。可以先执行以下命令（在对应文件夹下），然后再浏览器输入localhost:4000查看。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hexo g	#hexo generate</div><div class="line">$ hexo s	#hexo server</div></pre></td></tr></table></figure></p>
<h3 id="2-4-3-相关资料"><a href="#2-4-3-相关资料" class="headerlink" title="2.4.3 相关资料"></a>2.4.3 相关资料</h3><ul>
<li><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="external">Hexo 官方文档</a></li>
</ul>
<h1 id="三、一般的搭建方法"><a href="#三、一般的搭建方法" class="headerlink" title="三、一般的搭建方法"></a>三、一般的搭建方法</h1><p>在上面，我们已经配置好了所需的所有东西，也成功地搭建了一个本地Hexo博客。现在，需要使用GitHub Pages搭建一个别人能够访问的Hexo博客了。</p>
<p>3.1 使用默认theme</p>
<p>我们继续使用上面的文件夹F:\Hexo（也可以新建一个文件夹重新生成），然后编辑该文件夹下的_config.yml。</p>
<p>默认生成的_config.yml：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># Deployment</div><div class="line">## Docs: http://hexo.io/docs/deployment.html</div><div class="line">deploy:</div><div class="line">  type:</div></pre></td></tr></table></figure></p>
<p>修改后的_config.yml：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">deploy:</div><div class="line">  type: git</div><div class="line">  repo: 对应仓库的SSH地址（可以在GitHub对应的仓库中复制）</div><div class="line">  branch: 分支（User Pages为master，Project Pages为gh-pages）</div></pre></td></tr></table></figure></p>
<p>为了能够使Hexo部署到GitHub上，需要安装一个插件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ npm install hexo-deployer-git --save</div></pre></td></tr></table></figure></p>
<p>然后，执行下列指令即可完成部署：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>之后，可以通过在浏览器键入：username.github.io进行浏览，开心吧~</p>
<h2 id="3-2-其他theme"><a href="#3-2-其他theme" class="headerlink" title="3.2 其他theme"></a>3.2 其他theme</h2><p>如果想要使用其他主题，可以使用git clone将别人的主题拷贝到D:\Hexo\themes下，然后将_config.yml中的theme: landscape改为对应的主题名字。<br>详细步骤可以参考网上的指南。</p>
<p>landscape主题是Hexo自带的主题，不需要自己下载。</p>
<p>推荐两款比较好用的主题，NexT和Yelee</p>
<h1 id="四、优化和部署"><a href="#四、优化和部署" class="headerlink" title="四、优化和部署"></a>四、优化和部署</h1><h2 id="4-1-概述"><a href="#4-1-概述" class="headerlink" title="4.1 概述"></a>4.1 概述</h2><p>Hexo部署到GitHub上的文件，是.md（你的博文）转化之后的.html（静态网页）。因此，当你重装电脑或者想在不同电脑上修改博客时，就不可能了（除非你自己写html o(^▽^)o ）。</p>
<p>其实，Hexo生成的网站文件中有.gitignore文件，因此它的本意也是想我们将Hexo生成的网站文件存放到GitHub上进行管理的（而不是用U盘或者云备份啦(╬▔皿▔)凸）。这样，不仅解决了上述的问题，还可以通过git的版本控制追踪你的博文的修改过程，是极赞的。</p>
<p>但是，如果每一个GitHub Pages都需要创建一个额外的仓库来存放Hexo网站文件，我感觉很麻烦（10个项目需要20个仓库(ˉ▽ˉ；)…）。<br>所以，我利用了分支！！！</p>
<p>简单地说，每个想建立GitHub Pages的仓库，起码有两个分支，一个用来存放Hexo网站的文件，一个用来发布网站。</p>
<h2 id="4-2-我的博客搭建流程"><a href="#4-2-我的博客搭建流程" class="headerlink" title="4.2 我的博客搭建流程"></a>4.2 我的博客搭建流程</h2><p>下面以我的博客作为例子详细地讲述。</p>
<p>在本地电脑F盘下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">#第1步：</div><div class="line">mkdir hexo	//创建hexo文件夹</div><div class="line">cd hexo</div><div class="line"></div><div class="line">#第2步：</div><div class="line">hexo init</div><div class="line"></div><div class="line">#第3步:</div><div class="line">git@github.com:MOxFIVE/hexo-theme-yelee.git theme/yelee		#使用yelee主题</div><div class="line">cd theme/yelee	</div><div class="line">git remote rm origin	#删除yelee本地仓库与远程仓库的关联</div><div class="line">rm -rf .git		#删除yelee本地仓库的`.git`文件夹，事情称为普通文件夹</div><div class="line"></div><div class="line">#第4步</div><div class="line">#配置主题文件等 上面已经讲了，或者参考其他资料</div><div class="line">......</div><div class="line"></div><div class="line">#第5步：</div><div class="line">#修改配置文件中的deploy属性</div><div class="line">deploy:</div><div class="line">  type: git</div><div class="line">  repo: 对应仓库的SSH地址（可以在GitHub对应的仓库中复制）</div><div class="line">  branch: 分支（User Pages为master，Project Pages为gh-pages）</div><div class="line"></div><div class="line">#第6步：</div><div class="line">hexo d	#发布网站到GitHub中的master分支</div><div class="line">#现在就可以登录 `http:username.github.io访问自己的网站了。</div><div class="line"></div><div class="line">#第7步：使用backup分支备份博客文件，以便可以在其他电脑上写blog.</div><div class="line"></div><div class="line">#在F:\hexo目录下</div><div class="line">#将博客备份文件添加到git版本库中</div><div class="line">git init</div><div class="line">git add .</div><div class="line">git commit -m &quot;...&quot;</div><div class="line">#建立与远程仓库的连接</div><div class="line">git remote add origin git@github.com:freeshow/freeshow.github.io.git</div><div class="line"></div><div class="line">#这就是第3步中为什么将yelee仓库取消版本库的原因，因为要在它的父目录F:\hexo中创建版本库，</div><div class="line">如果不取消yelee主题的版本库，则提交hexo仓库时，没法将其下面的yelee仓库提交到远程仓库。</div><div class="line"></div><div class="line">#如果当yelee主题有更新时，在给yelee文件添加远程仓库连接，更新完yelee仓库时，在将yelee仓库的版本库删除即可。</div><div class="line"></div><div class="line">#将本地仓库推送到github下的backup分支。</div><div class="line">git push origin master:backup  #本地分支master到远程仓库backup</div></pre></td></tr></table></figure></p>
<p>注意：</p>
<blockquote>
<p>按上面步骤搭建完成后，需要将github中的backup分支设置成默认分支，<br>这样就可以在其他电脑上clone时，会默认把backup分支clone出来。</p>
</blockquote>
<h2 id="4-3-我的博客管理流程"><a href="#4-3-我的博客管理流程" class="headerlink" title="4.3 我的博客管理流程"></a>4.3 我的博客管理流程</h2><h3 id="4-3-1-日常修改"><a href="#4-3-1-日常修改" class="headerlink" title="4.3.1 日常修改"></a>4.3.1 日常修改</h3><p>在本地对博客进行修改（添加新博文、修改样式等等）后，通过下面的流程进行管理：</p>
<p>依次执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git add .</div><div class="line">git commit -m &quot;…&quot;</div><div class="line">git push origin master:backup</div></pre></td></tr></table></figure></p>
<p>将推送到GitHub（此时当前分支应为backup）.</p>
<p>然后才执行<code>hexo generate -d</code>发布网站到master分支上。</p>
<h3 id="4-3-2-本地资料丢失"><a href="#4-3-2-本地资料丢失" class="headerlink" title="4.3.2 本地资料丢失"></a>4.3.2 本地资料丢失</h3><p>当重装电脑之后，或者想在其他电脑上写博客，可以使用下列步骤：<br>1.使用git clone git@github.com:freeshow/freeshow.github.io.git拷贝仓库（默认分支为backup）；</p>
<p>2.在本地新拷贝的freeshow.github.io.git文件夹下通过Git bash依次执行下列指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">npm install hexo --save</div><div class="line">npm install</div><div class="line">#npm install hexo-deployer-git --save</div><div class="line">#在刚开始搭建博客时，已经执行了上面这条命令，则会将`hexo-deploy-get`依赖包，添加到`package.json`中去了，</div><div class="line">#故在上面执行`npm install`时，会安装`hexo-deploy-get`依赖包。</div><div class="line"></div><div class="line">#（记得，不需要hexo init这条指令）。hexo init会取消`freeshow.github.io.git`版本库</div><div class="line">#因为clone出的文件中已经包含建立网站所需要的所有文件。</div></pre></td></tr></table></figure></p>
<p>在其他电脑上clone出的backup分支，如果要日常修改，执行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">git add .</div><div class="line">git commit -m &quot;…&quot;</div><div class="line"></div><div class="line">#git push origin master:backup</div><div class="line">git push #本来就是从backup分支clone出来的，这样就相当于上面的提交到远程仓库。</div></pre></td></tr></table></figure></p>
<h1 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h1><p>忙了一上午，才把上面的 <code>四、优化部署</code> 搞明白，现在想想主要是不太熟悉git操作导致的。</p>
<p>哎，祝大家能够搭建出自己个性的博客。</p>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="综合" scheme="https://freeshow.github.io/categories/%E7%BB%BC%E5%90%88/"/>
    
    
      <category term="Hexo" scheme="https://freeshow.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫实例：登录豆瓣并修改签名</title>
    <link href="https://freeshow.github.io/Programming/Python/Python%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B%EF%BC%9A%E7%99%BB%E5%BD%95%E8%B1%86%E7%93%A3%E5%B9%B6%E4%BF%AE%E6%94%B9%E7%AD%BE%E5%90%8D/"/>
    <id>https://freeshow.github.io/Programming/Python/Python爬虫实例：登录豆瓣并修改签名/</id>
    <published>2016-07-24T13:23:12.000Z</published>
    <updated>2017-03-28T07:47:37.866Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h2><ul>
<li>登录豆瓣</li>
<li>修改签名</li>
</ul>
<h2 id="一、登录流程分析"><a href="#一、登录流程分析" class="headerlink" title="一、登录流程分析"></a>一、登录流程分析</h2><ul>
<li>向哪个url发送请求</li>
<li>发送哪些数据</li>
<li>有哪些特殊的头字段</li>
<li>验证码问题如何解决</li>
</ul>
<p>1.抓取豆瓣登录流程：</p>
<p>使用账号：xxxxxx 密码：xxxxxx 抓取得Network如下：</p>
<p>豆瓣登录界面网址：<code>https://www.douban.com/accounts/login</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line">General</div><div class="line"></div><div class="line">Request URL:https://accounts.douban.com/login</div><div class="line">Request Method:POST</div><div class="line">Status Code:302 Moved Temporarily</div><div class="line">Remote Address:211.147.4.32:443</div><div class="line"></div><div class="line">---------------------------------------------------------------------------</div><div class="line"></div><div class="line">Response Headers</div><div class="line"></div><div class="line">Cache-Control:must-revalidate, no-cache, private</div><div class="line">Connection:keep-alive</div><div class="line">Content-Length:65</div><div class="line">Content-Type:text/plain</div><div class="line">Date:Sat, 11 Jun 2016 02:48:18 GMT</div><div class="line">Expires:Sun, 1 Jan 2006 01:00:00 GMT</div><div class="line">Keep-Alive:timeout=30</div><div class="line">Location:https://www.douban.com</div><div class="line">P3P:CP=&quot;IDC DSP COR ADM DEVi TAIi PSA PSD IVAi IVDi CONi HIS OUR IND CNT&quot;</div><div class="line">Pragma:no-cache</div><div class="line">Server:dae</div><div class="line">Set-Cookie:ue=&quot;877646746@qq.com&quot;; domain=.douban.com; expires=Sun, 11-Jun-2017 02:48:18 GMT; httponly</div><div class="line">Set-Cookie:dbcl2=&quot;146925119:/crpdV7NiKQ&quot;; path=/; domain=.douban.com; httponly</div><div class="line">Set-Cookie:as=&quot;deleted&quot;; max-age=0; domain=.douban.com; expires=Thu, 01-Jan-1970 00:00:00 GMT</div><div class="line">Strict-Transport-Security:max-age=15552000;</div><div class="line">X-Content-Type-Options:nosniff</div><div class="line">X-DAE-App:accounts</div><div class="line">X-DAE-Node:sindar15a</div><div class="line">X-Douban-Mobileapp:0</div><div class="line">X-Frame-Options:SAMEORIGIN</div><div class="line">X-Xss-Protection:1; mode=block</div><div class="line"></div><div class="line">----------------------------------------------------------------------------------</div><div class="line"></div><div class="line">Request Headers</div><div class="line"></div><div class="line">Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</div><div class="line">Accept-Encoding:gzip, deflate, br</div><div class="line">Accept-Language:en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4</div><div class="line">Cache-Control:max-age=0</div><div class="line">Connection:keep-alive</div><div class="line">Content-Length:138</div><div class="line">Content-Type:application/x-www-form-urlencoded</div><div class="line">Cookie:bid=PHjUxRzrHNk; _vwo_uuid_v2=56A954C0557184C73BBB3DF5C8D30C1D|409597a19056d473ebee60708893e9b8; ap=1; ll=&quot;118221&quot;; __utmt=1; ps=y; __utma=30149280.2019919087.1465354115.1465606255.1465612975.3; __utmb=30149280.2.10.1465612975; __utmc=30149280; __utmz=30149280.1465612975.3.3.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; dbcl2=&quot;146925119:KHEcD+nREDs&quot;; ck=9R18</div><div class="line">Host:accounts.douban.com</div><div class="line">Origin:https://accounts.douban.com</div><div class="line">Referer:https://accounts.douban.com/login</div><div class="line">Upgrade-Insecure-Requests:1</div><div class="line">User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.84 Safari/537.36</div><div class="line">-------------------------------------------------------------</div><div class="line">Form Data</div><div class="line"></div><div class="line">ck:9R18</div><div class="line">source:None</div><div class="line">redir:https://www.douban.com</div><div class="line">form_email:877646746@qq.com</div><div class="line">form_password:song@3345616</div><div class="line">login:登录</div></pre></td></tr></table></figure>
<blockquote>
<p>即登录时，我们只需要模拟Request Headers中的头和Form Data中的post参数就可以登录了。</p>
<p>如果登录时，需要图片中的验证码，我们需要抽取验证码图片，然后手动填写上去。（半自动化方式）</p>
<p>当然，如果需要全自动化的方式，则需要用到机器学习中的知识，爬取所有验证码图片，然后训练模型，用机器学习的方法自动识别出验证码图片中的验证码。</p>
</blockquote>
<h2 id="二、修改签名流程分析"><a href="#二、修改签名流程分析" class="headerlink" title="二、修改签名流程分析"></a>二、修改签名流程分析</h2><ul>
<li>向哪个url发送请求</li>
<li>发送哪些数据</li>
<li>有哪些特殊的头字段</li>
<li>返回值长什么样</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">General</div><div class="line"></div><div class="line">Request URL:https://www.douban.com/j/people/146925119/edit_signature</div><div class="line">Request Method:POST</div><div class="line">Status Code:200 OK</div><div class="line">Remote Address:211.147.4.31:443</div><div class="line"></div><div class="line">--------------------------------------------------------------------------</div><div class="line">Response Headers</div><div class="line"></div><div class="line">Cache-Control:must-revalidate, no-cache, private</div><div class="line">Connection:keep-alive</div><div class="line">Content-Length:47</div><div class="line">Content-Type:application/json; charset=utf-8</div><div class="line">Date:Sat, 11 Jun 2016 06:06:37 GMT</div><div class="line">Expires:Sun, 1 Jan 2006 01:00:00 GMT</div><div class="line">Keep-Alive:timeout=30</div><div class="line">Pragma:no-cache</div><div class="line">Server:dae</div><div class="line">Strict-Transport-Security:max-age=15552000;</div><div class="line">X-DAE-App:sns</div><div class="line">X-DAE-Node:sindar25b</div><div class="line">X-Douban-Mobileapp:0</div><div class="line">X-Xss-Protection:1; mode=block</div><div class="line"></div><div class="line">-----------------------------------------------------------------------</div><div class="line">Request Headers</div><div class="line"></div><div class="line">Accept:application/json, text/javascript, */*; q=0.01</div><div class="line">Accept-Encoding:gzip, deflate, br</div><div class="line">Accept-Language:en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4</div><div class="line">Connection:keep-alive</div><div class="line">Content-Length:54</div><div class="line">Content-Type:application/x-www-form-urlencoded</div><div class="line">Cookie:bid=PHjUxRzrHNk; _vwo_uuid_v2=56A954C0557184C73BBB3DF5C8D30C1D|409597a19056d473ebee60708893e9b8; ll=&quot;118221&quot;; ps=y; ue=&quot;877646746@qq.com&quot;; dbcl2=&quot;146925119:/crpdV7NiKQ&quot;; ck=vkO3; ap=1; _pk_ref.100001.8cb4=%5B%22%22%2C%22%22%2C1465624694%2C%22https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DjUjRq0ldEsr3DVgcsr-2j6hhjW72VMHrsETjWL2QAee%26wd%3D%26eqid%3Dc07ebf420008142f00000003575b7a83%22%5D; __utmt=1; push_noty_num=0; push_doumail_num=0; _pk_id.100001.8cb4=cbb9346c7bb2e22f.1465354092.4.1465624911.1465613335.; _pk_ses.100001.8cb4=*; __utma=30149280.2019919087.1465354115.1465612975.1465624696.4; __utmb=30149280.4.10.1465624696; __utmc=30149280; __utmz=30149280.1465612975.3.3.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __utmv=30149280.14692</div><div class="line">Host:www.douban.com</div><div class="line">Origin:https://www.douban.com</div><div class="line">Referer:https://www.douban.com/people/146925119/</div><div class="line">User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.84 Safari/537.36</div><div class="line">X-Requested-With:XMLHttpRequest</div><div class="line"></div><div class="line">----------------------------------------------------------------------------</div><div class="line">Form Data</div><div class="line"></div><div class="line">ck:vkO3   </div><div class="line">signature:顶顶顶顶</div></pre></td></tr></table></figure>
<blockquote>
<p>Form Data</p>
<p>ck:vkO3<br>signature:顶顶顶顶</p>
</blockquote>
<p>当不知道post data中的值如何获得时，往往需要到操作页面的html源码中去寻找，如上面的</p>
<blockquote>
<p>ck:vk03<br>如要的操作页面的html的代码中寻找，然后把它解析出来。</p>
</blockquote>
<h2 id="实例："><a href="#实例：" class="headerlink" title="实例："></a>实例：</h2><p>注意：</p>
<p>本实例是基于登录时有图片验证码的，现在登录豆瓣好像不需要图片验证码了；</p>
<p>如果登录不需要验证码，则把验证码部分去掉即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line"># -*- coding: utf-8 -*-</div><div class="line">from HTMLParser import HTMLParser</div><div class="line">import requests</div><div class="line"></div><div class="line"></div><div class="line">def _attr(attrs, attrname):</div><div class="line">    for attr in attrs:</div><div class="line">        if attr[0] == attrname:</div><div class="line">            return attr[1]</div><div class="line">    return None</div><div class="line"></div><div class="line">#获得验证码信息</div><div class="line">def _get_captcha(content):</div><div class="line">    class CaptchaParser(HTMLParser):</div><div class="line">        def __init__(self):</div><div class="line">            HTMLParser.__init__(self)</div><div class="line">            self.captcha_id = None</div><div class="line">            self.captcha_url = None</div><div class="line"></div><div class="line">        def handle_starttag(self, tag, attrs):</div><div class="line">            if tag == &apos;input&apos; and _attr(attrs,&apos;type&apos;) == &apos;hidden&apos; and _attr(attrs,&apos;name&apos;) == &apos;captcha_id&apos;:</div><div class="line">                self.captcha_id = _attr(attrs,&apos;value&apos;)</div><div class="line">            if tag == &apos;image&apos; and _attr(attrs,&apos;id&apos;) == &apos;captcha_image&apos; and _attr(attrs,&apos;class&apos;) == &apos;captcha_image&apos;:</div><div class="line">                self.captcha_url == _attr(attrs,&apos;src&apos;)</div><div class="line"></div><div class="line">    p = CaptchaParser()</div><div class="line">    p.feed(content)</div><div class="line">    return p.captcha_id, p.captcha_url</div><div class="line"></div><div class="line">#获得ck属性的值</div><div class="line">def _get_ck(content):</div><div class="line">    class CKParser(HTMLParser):</div><div class="line">        def __init__(self):</div><div class="line">            HTMLParser.__init__(self)</div><div class="line">            self.ck = None</div><div class="line"></div><div class="line">        def handle_starttag(self, tag, attrs):</div><div class="line">            if tag == &apos;input&apos; and _attr(attrs,&apos;type&apos;) == &apos;hidden&apos; and _attr(attrs,&apos;name&apos;) == &apos;ck&apos;:</div><div class="line">                self.ck = _attr(attrs,&apos;value&apos;)</div><div class="line"></div><div class="line">    p =CKParser()</div><div class="line">    p.feed(content)</div><div class="line">    return p.ck</div><div class="line"></div><div class="line"></div><div class="line">class DoubanClient(object):</div><div class="line">    def __init__(self):</div><div class="line">        object.__init__(self)</div><div class="line">        headers = &#123;&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.84 Safari/537.36&apos;,</div><div class="line">                   &apos;origin&apos;:&apos;http/www.douban.com&apos;&#125;</div><div class="line">        #create requests session</div><div class="line">        self.session = requests.session()</div><div class="line">        #对session的头进行定制，这样以后，以后所有的请求都会包含上面headers中的数据</div><div class="line">        self.session.headers.update(headers)</div><div class="line"></div><div class="line">    #登录豆瓣</div><div class="line">    def login(self,username,password,source=&apos;index_nav&apos;,</div><div class="line">              redir = &apos;http://www.douban.com/&apos;,login = &apos;登录&apos;):</div><div class="line">        url = &apos;https://www.douban.com/accounts/login&apos;</div><div class="line">        #access login page to get captcha</div><div class="line">        #湖区登录界面中的验证码图片</div><div class="line">        #r = requests.get(url)</div><div class="line">        #应为登录和修改签名在同一个session中，故使用session.get(url)的方式登录</div><div class="line">        r = self.session.get(url)</div><div class="line">        (captcha_id,captcha_url) = _get_captcha(r.content)</div><div class="line">        if captcha_id:</div><div class="line">            captcha_solution = raw_input(&apos;please input solution for [%s]&apos; % captcha_url)</div><div class="line"></div><div class="line">        #post login request</div><div class="line">        data = &#123;&apos;from_email&apos;:username,&apos;from_passwd&apos;:password,&apos;source&apos;:source,</div><div class="line">                &apos;redir&apos;:redir,&apos;login&apos;:login&#125;</div><div class="line">        #将验证信息加入到post data中</div><div class="line">        if captcha_id:</div><div class="line">            data[&apos;captcha_id&apos;] = captcha_id</div><div class="line">            data[&apos;captcha_url&apos;] = captcha_url</div><div class="line"></div><div class="line">        headers = &#123;&apos;referer&apos;:&apos;http://www.douban.com/accounts/login?source=main&apos;,</div><div class="line">                   &apos;host&apos;:&apos;accounts.douban.com&apos;&#125;</div><div class="line">        #r = requests.post(url,data=data,headers=headers)</div><div class="line">        r = self.session.post(url,data=data,headers=headers)</div><div class="line">        print self.session.cookies.items()</div><div class="line">    </div><div class="line">    #编辑签名</div><div class="line">    def edit_signature(self,username,signature):</div><div class="line">        #access user&apos;s homepage</div><div class="line">        url = &apos;https://www.douban.com/people/%s/&apos; % username</div><div class="line">        r  = self.session.get(url)</div><div class="line">        #从操作页面的HTML代码中获取post data数据中参数ck的值</div><div class="line">        ck = _get_ck(r.content)</div><div class="line"></div><div class="line">        #post request to change signature</div><div class="line">        url = &apos;https://www.douban.com/j/people/%s/edit_signature&apos; % username</div><div class="line">        headers = &#123;&apos;referer&apos;:url,&apos;host&apos;:&apos;www.douban.com&apos;,</div><div class="line">                 &apos;x-requested-with&apos;:&apos;XMLHTTPRequest&apos;&#125;</div><div class="line">        data = &#123;&apos;ck&apos;:ck,&apos;signature&apos;:signature&#125;</div><div class="line">        r = self.session.post(url,data=data,headers=headers)</div><div class="line">        print r.content</div><div class="line"></div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    c = DoubanClient()</div><div class="line">    c.login(&apos;877646746@qq.com&apos;,&apos;song@3345616&apos;)</div><div class="line">    c.edit_signature(&apos;146925119&apos;,&apos;Hello&apos;)</div></pre></td></tr></table></figure>
<h2 id="四、作业"><a href="#四、作业" class="headerlink" title="四、作业"></a>四、作业</h2><ul>
<li>登录知乎</li>
<li>修改个人简介</li>
</ul>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="编程语言" scheme="https://freeshow.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="Crawler" scheme="https://freeshow.github.io/tags/Crawler/"/>
    
      <category term="Python" scheme="https://freeshow.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫实例：用requests重构豆瓣热播电影爬虫</title>
    <link href="https://freeshow.github.io/Programming/Python/Python%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B%EF%BC%9A%E7%94%A8requests%E9%87%8D%E6%9E%84%E8%B1%86%E7%93%A3%E7%83%AD%E6%92%AD%E7%94%B5%E5%BD%B1%E7%88%AC%E8%99%AB/"/>
    <id>https://freeshow.github.io/Programming/Python/Python爬虫实例：用requests重构豆瓣热播电影爬虫/</id>
    <published>2016-07-24T13:20:50.000Z</published>
    <updated>2017-03-28T07:46:56.362Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="功能："><a href="#功能：" class="headerlink" title="功能："></a>功能：</h2><ul>
<li>用requests重新实现豆瓣热播电影（原先用的是urllib,urlib2）</li>
<li>增加功能：下载每一个电影的海报图片</li>
</ul>
<h2 id="分析海报图片在HTML代码中的格式"><a href="#分析海报图片在HTML代码中的格式" class="headerlink" title="分析海报图片在HTML代码中的格式"></a>分析海报图片在HTML代码中的格式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&lt;li id=&quot;2131940&quot; class=&quot;list-item&quot; data-title=&quot;魔兽&quot; data-score=&quot;8.2&quot; data-star=&quot;40&quot; data-release=&quot;2016&quot; data-duration=&quot;124分钟&quot; data-region=&quot;美国 中国大陆 加拿大&quot; data-director=&quot;邓肯·琼斯&quot; data-actors=&quot;崔维斯·费米尔 / 托比·凯贝尔 / 宝拉·巴顿&quot; data-category=&quot;nowplaying&quot; data-enough=&quot;True&quot; data-showed=&quot;True&quot; data-votecount=&quot;63034&quot; data-subject=&quot;2131940&quot;&gt;</div><div class="line">    &lt;ul class=&quot;&quot;&gt;</div><div class="line">        &lt;li class=&quot;poster&quot;&gt;</div><div class="line">            &lt;a href=&quot;https://movie.douban.com/subject/2131940/?from=playing_poster&quot; class=&quot;ticket-btn&quot; target=&quot;_blank&quot; data-psource=&quot;poster&quot;&gt;</div><div class="line">                &lt;img src=&quot;https://img1.doubanio.com/view/movie_poster_cover/mpst/public/p2345947329.jpg&quot; alt=&quot;魔兽&quot; rel=&quot;nofollow&quot; class=&quot;&quot;&gt;</div><div class="line">            &lt;/a&gt;</div><div class="line">        &lt;/li&gt;</div><div class="line"></div><div class="line">    &lt;/ul&gt;</div></pre></td></tr></table></figure>
<p>每个电影的海报图片url在爬取的其电影用的<li>标签，的内部。</li></p>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> HTMLParser <span class="keyword">import</span> HTMLParser</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieParser</span><span class="params">(HTMLParser)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        HTMLParser.__init__(self)</div><div class="line">        self.movies=[]</div><div class="line">        self.in_movies = <span class="keyword">False</span></div><div class="line">    <span class="comment">#重载父类方法</span></div><div class="line">    <span class="comment">#循环处理feed进来的所有的tag,以及标签对应的attrs</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle_starttag</span><span class="params">(self, tag, attrs)</span>:</span></div><div class="line">        <span class="comment">#给定tag的属性名attrname，获取属性的值</span></div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">_attr</span><span class="params">(attrList,attrname)</span>:</span></div><div class="line">            <span class="keyword">for</span> attr <span class="keyword">in</span> attrList:</div><div class="line">                <span class="keyword">if</span> attr[<span class="number">0</span>] == attrname:</div><div class="line">                    <span class="keyword">return</span> attr[<span class="number">1</span>]</div><div class="line">            <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> tag == <span class="string">'li'</span> <span class="keyword">and</span> _attr(attrs,<span class="string">'data-title'</span>) \</div><div class="line">                <span class="keyword">and</span> _attr(attrs,<span class="string">'data-category'</span>) == <span class="string">'nowplaying'</span>:</div><div class="line">            movie = &#123;&#125;</div><div class="line">            movie[<span class="string">'title'</span>] = _attr(attrs,<span class="string">'data-title'</span>)</div><div class="line">            movie[<span class="string">'score'</span>] = _attr(attrs,<span class="string">'data-score'</span>)</div><div class="line">            movie[<span class="string">'director'</span>] = _attr(attrs,<span class="string">'data-director'</span>)</div><div class="line">            movie[<span class="string">'actors'</span>] = _attr(attrs,<span class="string">'data-actors'</span>)</div><div class="line">            self.movies.append(movie)</div><div class="line">            self.in_movies = <span class="keyword">True</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> tag == <span class="string">'img'</span> <span class="keyword">and</span> self.in_movies:</div><div class="line">            src = _attr(attrs,<span class="string">'src'</span>)</div><div class="line">            movie = self.movies[len(self.movies)<span class="number">-1</span>]</div><div class="line">            <span class="comment">#将电影的海报url添加到movie中</span></div><div class="line">            movie[<span class="string">'poster-url'</span>] = src</div><div class="line">            <span class="comment">#根据海报的url下载图片</span></div><div class="line">            _download_poster_image(movie)</div><div class="line">            <span class="comment">#下载完后将self.in_movies属性置为False</span></div><div class="line">            self.in_movies = <span class="keyword">False</span></div><div class="line"></div><div class="line"><span class="comment">#根据海报图片的url下载海报图片</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_download_poster_image</span><span class="params">(movie)</span>:</span></div><div class="line">    <span class="comment">#"poster-url":"https://img3.doubanio.com/view/movie_poster_cover/mpst/public/p2354707516.jpg",</span></div><div class="line">    src = movie[<span class="string">'poster-url'</span>]</div><div class="line">    r = requests.get(src)</div><div class="line">    fname = src.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</div><div class="line">    <span class="comment">#将图片下如文件</span></div><div class="line">    <span class="keyword">with</span> open(fname,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">        f.write(r.content)</div><div class="line">        movie[<span class="string">'poster-path'</span>] = fname</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#获取热播电影信息</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nowplaying_movies</span><span class="params">(url)</span>:</span></div><div class="line">    headlers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.84 Safari/537.36'</span>&#125;</div><div class="line"></div><div class="line">    <span class="comment"># req = urllib2.Request(url,headers=headlers)</span></div><div class="line">    <span class="comment"># response = urllib2.urlopen(req)</span></div><div class="line">    <span class="comment"># #定义解析器MovieParser继承自HTMLParser</span></div><div class="line">    <span class="comment"># parser = MovieParser()</span></div><div class="line">    <span class="comment"># #将response.read()喂给解析器，</span></div><div class="line">    <span class="comment"># # 供解析器的handle_startendtag(self, tag, attrs)解析</span></div><div class="line">    <span class="comment"># parser.feed(response.read())</span></div><div class="line">    <span class="comment"># response.close()</span></div><div class="line">    <span class="comment"># return parser.movies</span></div><div class="line"></div><div class="line">    <span class="comment">#使用requests重构上面注释的代码</span></div><div class="line">    r = requests.get(url,headlers)</div><div class="line">    p = MovieParser()</div><div class="line">    p.feed(r.content)</div><div class="line">    <span class="keyword">return</span> p.movies</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    url = <span class="string">'https://movie.douban.com/nowplaying/qingdao/'</span></div><div class="line">    movies = nowplaying_movies(url)</div><div class="line"></div><div class="line">    <span class="comment">#把movies以json格式打印出来</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'%s'</span> % json.dumps(movies,sort_keys=<span class="keyword">True</span>,indent=<span class="number">4</span>,separators=(<span class="string">','</span>,<span class="string">':'</span>))</div></pre></td></tr></table></figure>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="编程语言" scheme="https://freeshow.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="Crawler" scheme="https://freeshow.github.io/tags/Crawler/"/>
    
      <category term="Python" scheme="https://freeshow.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫实例：豆瓣热播电影（urllib+urllib2）</title>
    <link href="https://freeshow.github.io/Programming/Python/Python%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8B%EF%BC%9A%E8%B1%86%E7%93%A3%E7%83%AD%E6%92%AD%E7%94%B5%E5%BD%B1/"/>
    <id>https://freeshow.github.io/Programming/Python/Python爬虫实例：豆瓣热播电影/</id>
    <published>2016-07-24T13:11:57.000Z</published>
    <updated>2017-03-28T07:47:18.979Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="第1步：热播电影格式"><a href="#第1步：热播电影格式" class="headerlink" title="第1步：热播电影格式"></a>第1步：热播电影格式</h2><ol>
<li>使用Chrome打开也爬取的网页，打开Chrome的开发者选项，点击下图中的按钮!<img src="http://i.imgur.com/kmaPcJH.png" alt=""><br>，选中要爬取的区域，然后查看html代码，查看抽取内容的格式。</li>
</ol>
<p>通过上面方法找到热播电影的格式为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">&lt;div class=&quot;mod-bd&quot;&gt;</div><div class="line">           &lt;ul class=&quot;lists&quot;&gt;</div><div class="line">                   &lt;li</div><div class="line">                       id=&quot;2131940&quot;</div><div class="line">                       class=&quot;list-item&quot;</div><div class="line">                       data-title=&quot;魔兽&quot;</div><div class="line">                       data-score=&quot;8.2&quot;</div><div class="line">                       data-star=&quot;40&quot;</div><div class="line">                       data-release=&quot;2016&quot;</div><div class="line">                       data-duration=&quot;124分钟&quot;</div><div class="line">                       data-region=&quot;美国 中国大陆 加拿大&quot;</div><div class="line">                       data-director=&quot;邓肯·琼斯&quot;</div><div class="line">                       data-actors=&quot;崔维斯·费米尔 / 托比·凯贝尔 / 宝拉·巴顿&quot;</div><div class="line">                       data-category=&quot;nowplaying&quot;</div><div class="line">                       data-enough=&quot;True&quot;</div><div class="line">                       data-showed=&quot;True&quot;</div><div class="line">                       data-votecount=&quot;59747&quot;</div><div class="line">                       data-subject=&quot;2131940&quot;</div><div class="line">                   &gt;</div><div class="line">                   &lt;li</div><div class="line">                       id=&quot;25786060&quot;</div><div class="line">                       class=&quot;list-item&quot;</div><div class="line">                       data-title=&quot;X战警：天启&quot;</div><div class="line">                       data-score=&quot;8.2&quot;</div><div class="line">                       data-star=&quot;40&quot;</div><div class="line">                       data-release=&quot;2016&quot;</div><div class="line">                       data-duration=&quot;144分钟&quot;</div><div class="line">                       data-region=&quot;美国&quot;</div><div class="line">                       data-director=&quot;布莱恩·辛格&quot;</div><div class="line">                       data-actors=&quot;詹姆斯·麦卡沃伊 / 迈克尔·法斯宾德 / 詹妮弗·劳伦斯&quot;</div><div class="line">                       data-category=&quot;nowplaying&quot;</div><div class="line">                       data-enough=&quot;True&quot;</div><div class="line">                       data-showed=&quot;True&quot;</div><div class="line">                       data-votecount=&quot;82158&quot;</div><div class="line">                       data-subject=&quot;25786060&quot;</div><div class="line">                   &gt;</div><div class="line">                   。。。。。。</div></pre></td></tr></table></figure>
<p>因此，我们只需要拿到所有<li>标签中属性data-category=”nowplaying”的data-title属性，就可获得热播电影。</li></p>
<h2 id="HTMLParse简介"><a href="#HTMLParse简介" class="headerlink" title="HTMLParse简介"></a>HTMLParse简介</h2><ul>
<li>feed：向解析器(HTMLParse)中喂数据，可以分段提供</li>
<li>handler_starttag：处理html的开始标签<ul>
<li>tag：标签名称</li>
<li>attrs：标签属性列表</li>
</ul>
</li>
<li>handler_data：处理标签里的数据体</li>
<li>data：数据文本</li>
</ul>
<h2 id="第2步通过HTMLParser解析器解析网页html代码，获取所有信息"><a href="#第2步通过HTMLParser解析器解析网页html代码，获取所有信息" class="headerlink" title="第2步通过HTMLParser解析器解析网页html代码，获取所有信息"></a>第2步通过HTMLParser解析器解析网页html代码，获取所有信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">from</span> HTMLParser <span class="keyword">import</span> HTMLParser</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieParser</span><span class="params">(HTMLParser)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        HTMLParser.__init__(self)</div><div class="line">        self.movies=[]</div><div class="line">    <span class="comment">#重载父类方法</span></div><div class="line">    <span class="comment">#循环处理feed进来的所有的tag,以及标签对应的attrs</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle_starttag</span><span class="params">(self, tag, attrs)</span>:</span></div><div class="line">        <span class="comment">#给定tag的属性名attrname，获取属性的值</span></div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">_attr</span><span class="params">(attrList,attrname)</span>:</span></div><div class="line">            <span class="keyword">for</span> attr <span class="keyword">in</span> attrList:</div><div class="line">                <span class="keyword">if</span> attr[<span class="number">0</span>] == attrname:</div><div class="line">                    <span class="keyword">return</span> attr[<span class="number">1</span>]</div><div class="line">            <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="keyword">if</span> tag == <span class="string">'li'</span> <span class="keyword">and</span> _attr(attrs,<span class="string">'data-title'</span>) \</div><div class="line">                <span class="keyword">and</span> _attr(attrs,<span class="string">'data-category'</span>) == <span class="string">'nowplaying'</span>:</div><div class="line">            movie = &#123;&#125;</div><div class="line">            movie[<span class="string">'title'</span>] = _attr(attrs,<span class="string">'data-title'</span>)</div><div class="line">            movie[<span class="string">'score'</span>] = _attr(attrs,<span class="string">'data-score'</span>)</div><div class="line">            movie[<span class="string">'director'</span>] = _attr(attrs,<span class="string">'data-director'</span>)</div><div class="line">            movie[<span class="string">'actors'</span>] = _attr(attrs,<span class="string">'data-actors'</span>)</div><div class="line">            self.movies.append(movie)</div><div class="line">            </div><div class="line"><span class="comment">#获取热播电影信息</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nowplaying_movies</span><span class="params">(url)</span>:</span></div><div class="line">    headlers = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.84 Safari/537.36'</span>&#125;</div><div class="line">    req = urllib2.Request(url,headers=headlers)</div><div class="line">    response = urllib2.urlopen(req)</div><div class="line">    <span class="comment">#定义解析器MovieParser继承自HTMLParser</span></div><div class="line">    parser = MovieParser()</div><div class="line">    <span class="comment">#将response.read()喂给解析器，</span></div><div class="line">    <span class="comment"># 供解析器的handle_startendtag(self, tag, attrs)解析</span></div><div class="line">    parser.feed(response.read())</div><div class="line">    response.close()</div><div class="line">    <span class="keyword">return</span> parser.movies</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    url = <span class="string">'https://movie.douban.com/nowplaying/qingdao/'</span></div><div class="line">    movies = nowplaying_movies(url)</div><div class="line"></div><div class="line">    <span class="comment">#把movies以json格式打印出来</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'%s'</span> % json.dumps(movies,sort_keys=<span class="keyword">True</span>,indent=<span class="number">4</span>,separators=(<span class="string">','</span>,<span class="string">':'</span>))</div></pre></td></tr></table></figure>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="编程语言" scheme="https://freeshow.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="Crawler" scheme="https://freeshow.github.io/tags/Crawler/"/>
    
      <category term="Python" scheme="https://freeshow.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python爬虫之requests介绍</title>
    <link href="https://freeshow.github.io/Programming/Python/Python%E7%88%AC%E8%99%AB%E4%B9%8Brequests%E4%BB%8B%E7%BB%8D/"/>
    <id>https://freeshow.github.io/Programming/Python/Python爬虫之requests介绍/</id>
    <published>2016-07-24T13:05:18.000Z</published>
    <updated>2017-03-28T07:46:36.796Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="一、基本介绍"><a href="#一、基本介绍" class="headerlink" title="一、基本介绍"></a>一、基本介绍</h2><p><a href="http://requests.readthedocs.io/en/latest/" target="_blank" rel="external">requsets官网地址</a></p>
<h4 id="和urllib、urllib2的区别："><a href="#和urllib、urllib2的区别：" class="headerlink" title="和urllib、urllib2的区别："></a>和urllib、urllib2的区别：</h4><ul>
<li>requests不是标准库</li>
<li>最好用的http库，pythonic风格</li>
</ul>
<h4 id="安装：pip-install-requests"><a href="#安装：pip-install-requests" class="headerlink" title="安装：pip install requests"></a>安装：pip install requests</h4><h2 id="二、requests请求"><a href="#二、requests请求" class="headerlink" title="二、requests请求"></a>二、requests请求</h2><h3 id="1-requests-request-method-url-kwargs"><a href="#1-requests-request-method-url-kwargs" class="headerlink" title="1.requests.request(method, url, **kwargs)"></a>1.requests.request(method, url, **kwargs)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">requests.request(method, url, **kwargs)</div><div class="line">    Constructs and sends a Request. Returns Response object.</div></pre></td></tr></table></figure>
<p><strong>参数：</strong></p>
<ul>
<li>method – method for the new Request object.(get/post/head/put/delete)<br>url – URL for the new Request object.</li>
<li>params – (optional) Dictionary or bytes to be sent in the query string for the Request.(请求参数)</li>
<li>data – (optional) Dictionary, bytes, or file-like object to send in the body of the Request.</li>
<li>json – (optional) json data to send in the body of the Request.</li>
<li>headers – (optional) Dictionary of HTTP Headers to send with the Request.</li>
<li>cookies – (optional) Dict or CookieJar object to send with the Request.</li>
<li>files – (optional) Dictionary of ‘name’: file-like-objects (or {‘name’: file-tuple}) for multipart encoding upload. file-tuple can be a 2-tuple (‘filename’, fileobj), 3-tuple (‘filename’, fileobj, ‘content_type’) or a 4-tuple (‘filename’, fileobj, ‘content_type’, custom_headers), where ‘content-type’ is a string defining the content type of the given file and custom_headers a dict-like object containing additional headers to add for the file.</li>
<li>auth – (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.</li>
<li>timeout (float or tuple) – (optional) How long to wait for the server to send data before giving up, as a float, or a (connect timeout, read timeout) tuple.</li>
<li>allow_redirects (bool) – (optional) Boolean. Set to True if POST/PUT/DELETE redirect following is allowed.</li>
<li>proxies – (optional) Dictionary mapping protocol to the URL of the proxy.</li>
<li>verify – (optional) whether the SSL cert will be verified. A CA_BUNDLE path can also be provided. Defaults to True.</li>
<li>stream – (optional) if False, the response content will be immediately downloaded.</li>
<li>cert – (optional) if String, path to ssl client cert file (.pem). If Tuple, (‘cert’, ‘key’) pair.(验证证书)</li>
</ul>
<p><strong>Return</strong>：requests.Response</p>
<p><strong>Usage</strong>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import requests</div><div class="line">&gt;&gt;&gt; req = requests.request(&apos;GET&apos;, &apos;http://httpbin.org/get&apos;)</div><div class="line">&lt;Response [200]&gt;</div></pre></td></tr></table></figure>
<h3 id="2-requests-get"><a href="#2-requests-get" class="headerlink" title="2.requests.get()"></a>2.requests.get()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">requests.get(url, params=None, **kwargs)</div><div class="line">    Sends a GET request.</div></pre></td></tr></table></figure>
<h3 id="3-requests-post"><a href="#3-requests-post" class="headerlink" title="3.requests.post()"></a>3.requests.post()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">requests.post(url, data=None, json=None, **kwargs)</div><div class="line">    Sends a POST request.</div></pre></td></tr></table></figure>
<h3 id="4-requests-head"><a href="#4-requests-head" class="headerlink" title="4.requests.head()"></a>4.requests.head()</h3><h3 id="5-requests-put"><a href="#5-requests-put" class="headerlink" title="5.requests.put()"></a>5.requests.put()</h3><h2 id="二、requests应答"><a href="#二、requests应答" class="headerlink" title="二、requests应答"></a>二、requests应答</h2><ul>
<li>status_code：状态码</li>
<li>headers：应答得http头</li>
<li>json：应答得json数据</li>
<li>text：应答得Unicode编码的文本</li>
<li>content：应答得字节流数据</li>
<li>cookies：应担的cookies，自动处理。</li>
</ul>
<h2 id="三、基本用法"><a href="#三、基本用法" class="headerlink" title="三、基本用法"></a>三、基本用法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"># -*- coding: utf-8 -*-</div><div class="line">import requests</div><div class="line"></div><div class="line">def get_json():</div><div class="line">    response = requests.get(&apos;https://api.github.com/events&apos;)</div><div class="line">    print response.status_code</div><div class="line">    #print response.headers</div><div class="line">    #print response.content</div><div class="line">    #print response.text</div><div class="line">    print response.json()</div><div class="line"></div><div class="line">def get_querystring():</div><div class="line">    #http://httpbin.org是专门测试http的网站</div><div class="line">    url = &apos;http://httpbin.org/get&apos;</div><div class="line">    params = &#123;&apos;qs1&apos;:&apos;value1&apos;,&apos;qs2&apos;:&apos;value2&apos;&#125;</div><div class="line">    r = requests.get(url,params=params)</div><div class="line">    print r.status_code</div><div class="line">    print r.content</div><div class="line"></div><div class="line">def get_custom_headers():</div><div class="line">    url = &apos;http://httpbin.org/get&apos;</div><div class="line">    headers = &#123;&apos;x-header1&apos;:&apos;value1&apos;,&apos;x-header2&apos;:&apos;value2&apos;&#125;</div><div class="line">    r = requests.get(url,headers=headers)</div><div class="line">    print r.status_code</div><div class="line">    print r.content</div><div class="line"></div><div class="line">def get_cookie():</div><div class="line">    url = &apos;http://www.douban.com&apos;</div><div class="line">    headers = &#123;&apos;User-Agent&apos;:&apos;Chrome&apos;&#125;</div><div class="line">    r = requests.get(url,headers=headers)</div><div class="line">    print r.status_code</div><div class="line">    print r.cookies</div><div class="line">    #输出：&lt;RequestsCookieJar[&lt;Cookie bid=rnxfxUZLSxA for .douban.com/&gt;,</div><div class="line">    # &lt;Cookie ll=&quot;118221&quot; for .douban.com/&gt;]&gt;</div><div class="line">    print r.cookies[&apos;bid&apos;] #输出：zkXS0p3Zars</div><div class="line"></div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    #get_json()</div><div class="line">    #get_querystring()</div><div class="line">    #get_custom_headers()</div><div class="line">    get_cookie()</div></pre></td></tr></table></figure>
<h2 id="四、高级用法"><a href="#四、高级用法" class="headerlink" title="四、高级用法"></a>四、高级用法</h2><p>下面这些高级用法：自己看requests文档。</p>
<ul>
<li>Session：同一个会话内参数保持一致，且会重用TCP连接。也会尽量保持连接，也会提高性能</li>
<li>SSL证书认证：开启、关闭、自定义CA证书</li>
<li>上传普通文件和复杂结构的文件</li>
<li>代理访问</li>
</ul>
</the>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;Excerpt in index | 首页摘要&gt;&lt;br&gt;
    
    </summary>
    
      <category term="编程语言" scheme="https://freeshow.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="Crawler" scheme="https://freeshow.github.io/tags/Crawler/"/>
    
      <category term="Python" scheme="https://freeshow.github.io/tags/Python/"/>
    
  </entry>
  
</feed>
